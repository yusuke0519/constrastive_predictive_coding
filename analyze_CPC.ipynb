{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "気になっていること\n",
    "* PositiveとNegativeは実際どれくらい離れているのか\n",
    "* 特徴量は縮退していないか\n",
    "* 一部の次元だけで判断されていないか =>これはCMD的にも多分発生してはいなそうではある\n",
    "\n",
    "\n",
    "手法アイディア\n",
    "* ランダム行列を挟んだ上で、複数の重みでスコアを出す\n",
    "* Maximum Classifier Discrepancyみたいなことをする\n",
    "* Hard Negative以外は無視する（Positiveの最小スコアより低いNegativeについては信用しない） => 学習が遅くなりそう（初期で全く学習がされない？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_sacred import data_ingredient, method_ingredient, optim_ingredient\n",
    "from sacred import Experiment\n",
    "ex = Experiment('jupyter_ex', ingredients=[data_ingredient, method_ingredient, optim_ingredient], interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def main(_config):\n",
    "    print(_config)\n",
    "    return _config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - jupyter_ex - No observers have been added to this run\n",
      "INFO - jupyter_ex - Running command 'main'\n",
      "INFO - jupyter_ex - Started\n",
      "INFO - jupyter_ex - Result: {'seed': 123456, 'dataset': {'name': 'oppG', 'validation': 'ADL4-ADL5', 'test_domain': 'S1', 'L': 12, 'K': 5}, 'method': {'name': 'CPC', 'hidden': 1600, 'context': 800, 'num_gru': 1, 'sampler_mode': 'random', 'num_negative': 1, 'cont_type': 'sigmoid'}, 'optim': {'lr': 0.0001, 'num_batch': 10000, 'batch_size': 128}}\n",
      "INFO - jupyter_ex - Completed after 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 123456, 'dataset': {'name': 'oppG', 'validation': 'ADL4-ADL5', 'test_domain': 'S1', 'L': 12, 'K': 5}, 'method': {'name': 'CPC', 'hidden': 1600, 'context': 800, 'num_gru': 1, 'sampler_mode': 'random', 'num_negative': 1, 'cont_type': 'sigmoid'}, 'optim': {'lr': 0.0001, 'num_batch': 10000, 'batch_size': 128}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7fba120c31d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.run(config_updates={'seed':123456})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = {'seed': 123456, 'dataset': {'name': 'oppG', 'validation': 'ADL4-ADL5', 'test_domain': 'S1', 'L': 12, 'K': 5}, 'method': {'name': 'CPC', 'hidden': 1600, 'context': 800, 'num_gru': 1, 'sampler_mode': 'random'}, 'optim': {'lr': 0.0001, 'num_batch': 10000, 'batch_size': 128}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_sacred import *\n",
    "from sacred_wrap import MongoExtractor\n",
    "from utils import flatten_dict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_dataset(**_config['dataset'])\n",
    "train_dataset_joint, valid_dataset_joint, train_dataset_marginal, valid_dataset_marginal, test_dataset = datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 800\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model = get_model(input_shape=train_dataset_joint.get('input_shape'), K=_config['dataset']['K'], **_config['method'])\n",
    "query = deepcopy(_config)\n",
    "query = flatten_dict(query)\n",
    "extractor = MongoExtractor(None, 'CPC_test')\n",
    "result = list(extractor.find(query, ['config', 'info'], False, 'COMPLETED'))\n",
    "assert len(result) == 1, \"There are too many or no results. Please check the query {}\".format(query)\n",
    "result = result[0]\n",
    "\n",
    "path = os.path.join(result['info']['log_dir'], 'model_{}.pth'.format(_config['optim']['num_batch']))\n",
    "model = model.cpu()\n",
    "model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPCModel(\n",
       "  (g_enc): Encoder(\n",
       "    (feature): Sequential(\n",
       "      (0): Conv2d(1, 50, kernel_size=(1, 5), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(50, 40, kernel_size=(1, 5), stride=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(40, 20, kernel_size=(1, 3), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5)\n",
       "      (9): Flatten()\n",
       "      (10): Linear(in_features=4520, out_features=1600, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Dropout(p=0.5)\n",
       "    )\n",
       "  )\n",
       "  (c_enc): ContextEncoder(\n",
       "    (gru): GRU(1600, 800)\n",
       "  )\n",
       "  (predictor): Predictor(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=800, out_features=1600, bias=True)\n",
       "      (1): Linear(in_features=800, out_features=1600, bias=True)\n",
       "      (2): Linear(in_features=800, out_features=1600, bias=True)\n",
       "      (3): Linear(in_features=800, out_features=1600, bias=True)\n",
       "      (4): Linear(in_features=800, out_features=1600, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_joint = data.DataLoader(\n",
    "    train_dataset_joint, batch_size=12, shuffle=True)\n",
    "train_loader_marginal = data.DataLoader(\n",
    "    train_dataset_marginal, batch_size=12, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptimizer = optim.Adam(model.parameters(), lr=_config['optim']['lr'])\\nfor num_iter in range(100):\\n    loss = train_CPC(train_loader_joint, train_loader_marginal, model, optimizer)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=_config['optim']['lr'])\n",
    "for num_iter in range(100):\n",
    "    loss = train_CPC(train_loader_joint, train_loader_marginal, model, optimizer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataset_joint, dataset_marginal, model, num_eval=10, batch_size=128):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    loader_joint = data.DataLoader(dataset_joint, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    loader_marginal = data.DataLoader(dataset_marginal, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    if num_eval is None:\n",
    "        num_eval = len(loader_joint)\n",
    "\n",
    "    K = dataset_marginal.T\n",
    "    L = dataset_joint.T - K\n",
    "    losses = [0] * K\n",
    "    TP = [0] * K\n",
    "    TN = [0] * K\n",
    "    FP = [0] * K\n",
    "    FN = [0] * K\n",
    "\n",
    "    for i, ((X_j, _), (X_m, _)) in enumerate(zip(loader_joint, loader_marginal)):\n",
    "        X_j = X_j.float().cuda()\n",
    "        X_m = X_m.float().cuda()\n",
    "\n",
    "        score_j_list, score_m_list = model(X_j, X_m, L, K)\n",
    "        for k in range(K):\n",
    "            losses[k] += (-1.0 * torch.log(torch.clamp(score_j_list[k], min=1e-8)).mean()\n",
    "                          - torch.log(torch.clamp(1-score_m_list[k], min=1e-8)).mean()).item()\n",
    "            TP[k] += (score_j_list[k] > 0.5).sum().item()\n",
    "            TN[k] += (score_m_list[k] < 0.5).sum().item()\n",
    "            FP[k] += (score_m_list[k] > 0.5).sum().item()\n",
    "            FN[k] += (score_j_list[k] < 0.5).sum().item()\n",
    "        if i+1 == num_eval:\n",
    "            break\n",
    "    results = OrderedDict()\n",
    "    for i in range(K):\n",
    "        print(score_j_list[i].min(), score_m_list[i].max())\n",
    "\n",
    "    for k in range(K):\n",
    "        results['loss-{}'.format(k)] = losses[k] / (2*(i+1))\n",
    "        results['accuracy-{}'.format(k)] = float(TP[k]+TN[k]) / float(FP[k]+FN[k]+TP[k]+TN[k])\n",
    "\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9851, device='cuda:0', grad_fn=<MinBackward1>) tensor(-1.3982, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.6562, device='cuda:0', grad_fn=<MinBackward1>) tensor(-0.4716, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.8864, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.3559, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.8961, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.0562, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(2.6404, device='cuda:0', grad_fn=<MinBackward1>) tensor(5.0485, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "train_result = validate(train_dataset_joint, train_dataset_marginal, model, num_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpc import get_context\n",
    "\n",
    "X_j, _ = train_loader_joint.__iter__().__next__()\n",
    "X_m, _ = train_loader_marginal.__iter__().__next__()\n",
    "X_j = X_j.float().cuda()\n",
    "X_m = X_m.float().cuda()\n",
    "K = train_dataset_marginal.T\n",
    "L = train_dataset_joint.T - K\n",
    "\n",
    "c = get_context(X_j[..., :L], model.g_enc, model.c_enc)\n",
    "score_j = [None] * K\n",
    "score_m = [None] * K\n",
    "for i in range(K):\n",
    "    z_j = model.g_enc(X_j[..., L+i])\n",
    "    z_m = model.g_enc(X_m[..., i])\n",
    "    z_p = model.predictor(c, i)\n",
    "    score_j[i] = torch.sigmoid(torch.bmm(z_j.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))\n",
    "    score_m[i] = torch.sigmoid(torch.bmm(z_m.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19200, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.dropout(z_j, p=1.0)==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.bernoulli(z_j.data.new(z_j.data.size()).fill_(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.0\n",
    "num_mask = 10\n",
    "\n",
    "model.eval()\n",
    "score_j = [0] * K\n",
    "score_m = [0] * K\n",
    "for i in range(K):\n",
    "    z_j = model.g_enc(X_j[..., L+i])\n",
    "    z_m = model.g_enc(X_m[..., i])\n",
    "    z_p = model.predictor(c, i)\n",
    "    for j in range(num_mask):\n",
    "        mask = torch.bernoulli(z_j.data.new(z_j.data.size()).fill_(p))\n",
    "        # _z_j = (z_j * mask)\n",
    "        # _z_m = (z_m * mask)\n",
    "        _z_p =  (z_p * mask)\n",
    "        score_j[i] += 1.0/num_mask * torch.bmm(z_j.unsqueeze(1), _z_p.unsqueeze(2)).squeeze(2)\n",
    "        score_m[i] += 1.0/num_mask * torch.bmm(z_m.unsqueeze(1), _z_p.unsqueeze(2)).squeeze(2)\n",
    "model.train()\n",
    "score_j[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.bernoulli(z_j.data.new(z_j.data.size()).fill_(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
