{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_sacred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_per = 100\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name, validation, test_domain, L, K):\n",
    "    \"\"\"Prepare datasets for train, valid and test with configurations.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    name : str\n",
    "    validation : str or list\n",
    "    test_domain : str or list\n",
    "    L : int\n",
    "    K : int\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    {train/valid}_dataset_{joint/marginal} : torch.Dataset\n",
    "        {train/valid} datasets from {joint/marginal} distributions\n",
    "    \"\"\"\n",
    "    if isinstance(validation, str):\n",
    "        validation = validation.split('-')\n",
    "    all_adls = OppG.get('all_adls')\n",
    "    all_domain = OppG.get('all_domain_key')\n",
    "    train_adls = sorted(list(set(all_adls) - set(validation)))\n",
    "    train_domain = sorted(list(set(all_domain) - set([test_domain])))\n",
    "    train_dataset_joint = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K+L, adl_ids=train_adls)\n",
    "    valid_dataset_joint = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K+L, adl_ids=validation)\n",
    "\n",
    "    # marginal sample come from same datasets for simplicity\n",
    "    # Same train-valid split with joint dataset\n",
    "    train_dataset_marginal = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K, adl_ids=train_adls)\n",
    "    valid_dataset_marginal = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K, adl_ids=validation)\n",
    "    test_dataset = OppG(test_domain, l_sample=30, interval=15, T=K+L)\n",
    "    return train_dataset_joint, valid_dataset_joint, train_dataset_marginal, valid_dataset_marginal, test_dataset\n",
    "\n",
    "datasets = get_dataset('opp', 'ADL4-ADL5', 'S1', 12, 3)\n",
    "train_dataset_joint, valid_dataset_joint, train_dataset_marginal, valid_dataset_marginal, _ = datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JointとMarginalが必ず、別のユーザからサンプリングされるようにしたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "            \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        dataset_type = type(dataset)\n",
    "        for i in range(len(dataset.cummulative_sizes)):\n",
    "            if idx < i:\n",
    "                return i\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 10\n",
    "[x > 10 for x in train_dataset_joint.cumulative_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_joint, \n",
    "    sampler=ImbalancedDatasetSampler(train_dataset_joint),\n",
    "    batch_size=128, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+00, 3.2695e-05,  ..., 3.2695e-05, 3.2695e-05,\n",
       "        3.2695e-05], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.sampler.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "from torch._six import int_classes as _int_classes\n",
    "\n",
    "\n",
    "class SplitBatchSampler(Sampler):\n",
    "    r\"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
    "\n",
    "    Args:\n",
    "        sampler (Sampler): Base sampler.\n",
    "        batch_size (int): Size of mini-batch.\n",
    "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
    "            its size would be less than ``batch_size``\n",
    "\n",
    "    Example:\n",
    "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
    "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler, batch_size, drop_last):\n",
    "        for _sampler in sampler:\n",
    "            if not isinstance(_sampler, Sampler):\n",
    "                raise ValueError(\"sampler should be an instance of \"\n",
    "                                 \"torch.utils.data.Sampler, but got sampler={}\"\n",
    "                                 .format(_sampler))\n",
    "        if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\\n",
    "                batch_size <= 0:\n",
    "            raise ValueError(\"batch_size should be a positive integeral value, \"\n",
    "                             \"but got batch_size={}\".format(batch_size))\n",
    "        if not isinstance(drop_last, bool):\n",
    "            raise ValueError(\"drop_last should be a boolean value, but got \"\n",
    "                             \"drop_last={}\".format(drop_last))\n",
    "        self.sampler = sampler\n",
    "        self.num_sampler = len(sampler)\n",
    "        self.which_sampler = [int(batch_size/self.num_sampler*(i+1)) for i in range(self.num_sampler)]\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        sampler_idx = 0\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            idx = self.sampler[sampler_idx].__iter__().__next__()\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.which_sampler[sampler_idx]:\n",
    "                sampler_idx += 1\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.sampler) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        \n",
    "def get_split_samplers(dataset, ids):\n",
    "    assert len(dataset.datasets) == len(ids)\n",
    "    size = [0] + dataset.cummulative_sizes\n",
    "    sampler = []\n",
    "    for i in ids:\n",
    "        sampler.append(SubsetRandomSampler(range(size[i], size[i+1])))\n",
    "    return sampler\n",
    "\n",
    "sampler = get_split_samplers(train_dataset_joint, [0, 1, 2])\n",
    "batch_smpler = OriginalBatchSampler(get_split_samplers(train_dataset_joint, [0, 1, 2]), 128, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sampler = SubsetRandomSampler(range(train_dataset_joint.cummulative_sizes[0]))\n",
    "sampler1 = SubsetRandomSampler(range(100))\n",
    "sampler2 = SubsetRandomSampler(range(100, 200))\n",
    "batch_smpler = OriginalBatchSampler([sampler1, sampler2], 20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2409,\n",
       " 1773,\n",
       " 3697,\n",
       " 3843,\n",
       " 854,\n",
       " 1652,\n",
       " 3520,\n",
       " 8698,\n",
       " 1785,\n",
       " 6773,\n",
       " 9680,\n",
       " 990,\n",
       " 2891,\n",
       " 4658,\n",
       " 4597,\n",
       " 6586,\n",
       " 4500,\n",
       " 5134,\n",
       " 5490,\n",
       " 1702,\n",
       " 10220,\n",
       " 8117,\n",
       " 9658,\n",
       " 6475,\n",
       " 6345,\n",
       " 5165,\n",
       " 5300,\n",
       " 4352,\n",
       " 9746,\n",
       " 2685,\n",
       " 9617,\n",
       " 4197,\n",
       " 3058,\n",
       " 2646,\n",
       " 1298,\n",
       " 8865,\n",
       " 7031,\n",
       " 2558,\n",
       " 10215,\n",
       " 5750,\n",
       " 7704,\n",
       " 4784,\n",
       " 16847,\n",
       " 14490,\n",
       " 19986,\n",
       " 17321,\n",
       " 21335,\n",
       " 18366,\n",
       " 12224,\n",
       " 16873,\n",
       " 14565,\n",
       " 11454,\n",
       " 18061,\n",
       " 13758,\n",
       " 11899,\n",
       " 10827,\n",
       " 13605,\n",
       " 18330,\n",
       " 12468,\n",
       " 13337,\n",
       " 15614,\n",
       " 15197,\n",
       " 10677,\n",
       " 16573,\n",
       " 17441,\n",
       " 12106,\n",
       " 18419,\n",
       " 19984,\n",
       " 13413,\n",
       " 11579,\n",
       " 15240,\n",
       " 20550,\n",
       " 17100,\n",
       " 15673,\n",
       " 19191,\n",
       " 20734,\n",
       " 15744,\n",
       " 13460,\n",
       " 14184,\n",
       " 11431,\n",
       " 17909,\n",
       " 19065,\n",
       " 15606,\n",
       " 15780,\n",
       " 11314,\n",
       " 23498,\n",
       " 25296,\n",
       " 22388,\n",
       " 27062,\n",
       " 30561,\n",
       " 27505,\n",
       " 24021,\n",
       " 25745,\n",
       " 29287,\n",
       " 29628,\n",
       " 24752,\n",
       " 28805,\n",
       " 30065,\n",
       " 27145,\n",
       " 25280,\n",
       " 29870,\n",
       " 29502,\n",
       " 23850,\n",
       " 21695,\n",
       " 27547,\n",
       " 25488,\n",
       " 24700,\n",
       " 29961,\n",
       " 27605,\n",
       " 27172,\n",
       " 24338,\n",
       " 21548,\n",
       " 27679,\n",
       " 25102,\n",
       " 22709,\n",
       " 30109,\n",
       " 23304,\n",
       " 23318,\n",
       " 24571,\n",
       " 30478,\n",
       " 27075,\n",
       " 23724,\n",
       " 24848,\n",
       " 26241,\n",
       " 27456,\n",
       " 22557,\n",
       " 28561,\n",
       " 26478]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_smpler.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10616"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cummulative_sizes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: cummulative_sizes attribute is renamed to cumulative_sizes\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "size = [0] + dataset.cummulative_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10616, 21336, 30588]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
