{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sacred Objectからちゃんとデータを取り出す（普通にDone）\n",
    "* Sacred Objectを使って，アーチファクトを取り出す（Artifactは，正直形式がわからないので使わない．_run['info']['log_dir']を記録しておいて，普通にファイルパスで読み取る\n",
    "* 既にやってた実験をSacredの方に入れ込む方法を考える\n",
    "  (これはSacredのUI使う方が多分やりやすい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred_wrap import SacredRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = SacredRecords.from_mongo({'method.name': 'CPC'}, db_name='CPC_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dataset.K</th>\n",
       "      <th>dataset.L</th>\n",
       "      <th>dataset.name</th>\n",
       "      <th>dataset.test_domain</th>\n",
       "      <th>dataset.validation</th>\n",
       "      <th>db_name</th>\n",
       "      <th>method.context</th>\n",
       "      <th>method.hidden</th>\n",
       "      <th>method.name</th>\n",
       "      <th>method.num_gru</th>\n",
       "      <th>num_batch</th>\n",
       "      <th>optim.lr</th>\n",
       "      <th>seed</th>\n",
       "      <th>gpu</th>\n",
       "      <th>train-accuracy-0</th>\n",
       "      <th>train-accuracy-1</th>\n",
       "      <th>train-accuracy-2</th>\n",
       "      <th>train-accuracy-3</th>\n",
       "      <th>train-accuracy-4</th>\n",
       "      <th>train-loss-0</th>\n",
       "      <th>train-loss-1</th>\n",
       "      <th>train-loss-2</th>\n",
       "      <th>train-loss-3</th>\n",
       "      <th>train-loss-4</th>\n",
       "      <th>valid-accuracy-0</th>\n",
       "      <th>valid-accuracy-1</th>\n",
       "      <th>valid-accuracy-2</th>\n",
       "      <th>valid-accuracy-3</th>\n",
       "      <th>valid-accuracy-4</th>\n",
       "      <th>valid-loss-0</th>\n",
       "      <th>valid-loss-1</th>\n",
       "      <th>valid-loss-2</th>\n",
       "      <th>valid-loss-3</th>\n",
       "      <th>valid-loss-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>569573406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>626506959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8659565388655462]</td>\n",
       "      <td>[0.8397124474789915]</td>\n",
       "      <td>[0.8213465073529411]</td>\n",
       "      <td>[0.7990086659663865]</td>\n",
       "      <td>[0.7852054884453782]</td>\n",
       "      <td>[0.32969168523529996]</td>\n",
       "      <td>[0.37716894139762686]</td>\n",
       "      <td>[0.402674847665955]</td>\n",
       "      <td>[0.4339139825907074]</td>\n",
       "      <td>[0.4519882528972225]</td>\n",
       "      <td>[0.8697620738636364]</td>\n",
       "      <td>[0.8449041193181818]</td>\n",
       "      <td>[0.8236416903409091]</td>\n",
       "      <td>[0.8024680397727273]</td>\n",
       "      <td>[0.7904385653409091]</td>\n",
       "      <td>[0.3302096782082861]</td>\n",
       "      <td>[0.37672673470594664]</td>\n",
       "      <td>[0.40218221802603116]</td>\n",
       "      <td>[0.43194649199193175]</td>\n",
       "      <td>[0.44786749509247864]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  dataset.K  dataset.L dataset.name dataset.test_domain  ...          valid-loss-0           valid-loss-1           valid-loss-2           valid-loss-3           valid-loss-4\n",
       "0         128          5         12         oppG                  S1  ...                   NaN                    NaN                    NaN                    NaN                    NaN\n",
       "1         128          5         12         oppG                  S1  ...                   NaN                    NaN                    NaN                    NaN                    NaN\n",
       "2         128          5         12         oppG                  S1  ...                   NaN                    NaN                    NaN                    NaN                    NaN\n",
       "3         128          5         12         oppG                  S1  ...                   NaN                    NaN                    NaN                    NaN                    NaN\n",
       "4         128          5         12         oppG                  S1  ...                   NaN                    NaN                    NaN                    NaN                    NaN\n",
       "5         128          5         12         oppG                  S1  ...  [0.3302096782082861]  [0.37672673470594664]  [0.40218221802603116]  [0.43194649199193175]  [0.44786749509247864]\n",
       "\n",
       "[6 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['batch_size', 'dataset.K', 'dataset.L', 'dataset.name',\n",
       "       'dataset.test_domain', 'dataset.validation', 'db_name',\n",
       "       'method.context', 'method.hidden', 'method.name', 'method.num_gru',\n",
       "       'num_batch', 'optim.lr', 'seed', 'gpu', 'train-accuracy-0',\n",
       "       'train-accuracy-1', 'train-accuracy-2', 'train-accuracy-3',\n",
       "       'train-accuracy-4', 'train-loss-0', 'train-loss-1', 'train-loss-2',\n",
       "       'train-loss-3', 'train-loss-4', 'valid-accuracy-0', 'valid-accuracy-1',\n",
       "       'valid-accuracy-2', 'valid-accuracy-3', 'valid-accuracy-4',\n",
       "       'valid-loss-0', 'valid-loss-1', 'valid-loss-2', 'valid-loss-3',\n",
       "       'valid-loss-4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred_wrap import MongoExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = MongoExtractor(None, 'CPC_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'name': 'model_100', 'file_id': ObjectId('5c8227e3c2e4429a23cd8f91')}]\n"
     ]
    }
   ],
   "source": [
    "for result in extractor.find({}, ['config', 'info', 'artifacts'], False, 'COMPLETED'):\n",
    "    print(result['artifacts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5c8227e3c2e4429a23cd8f91')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['artifacts'][0]['file_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BytesIO at 0x7f27dadd7f10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BytesIO(object.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "object = result['artifacts'][0]['file_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"\\\\\\x82'\\xe3\\xc2\\xe4B\\x9a#\\xcd\\x8f\\x91\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object.binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x5c'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4384cf67501e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x5c'."
     ]
    }
   ],
   "source": [
    "torch.load(BytesIO(object.binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('g_enc.feature.0.weight',\n",
       "              tensor([[[[ 0.3408,  0.3574, -0.2391, -0.0107, -0.1773]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1770,  0.0149, -0.1720,  0.3187,  0.1107]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3341, -0.3146,  0.0644,  0.1334,  0.3570]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3835,  0.4188, -0.1426, -0.3475, -0.4034]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4408,  0.0305,  0.1534,  0.1102,  0.1254]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3855, -0.2602, -0.2690, -0.2770, -0.2174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3923,  0.0363,  0.1146, -0.2179, -0.1241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0818,  0.0483,  0.0910, -0.4127,  0.4356]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3986,  0.2562,  0.2383, -0.2341, -0.1554]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0018,  0.2794,  0.0324,  0.1969, -0.3488]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4365, -0.4427, -0.2812,  0.0017, -0.4316]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4296,  0.1700,  0.0662,  0.0907,  0.1797]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3176,  0.2144, -0.3702,  0.0171, -0.3368]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3383, -0.4440, -0.1294,  0.1854,  0.1900]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0426, -0.2049, -0.4239, -0.3960,  0.0012]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2650, -0.3331, -0.3486, -0.0056, -0.3285]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1913,  0.3130,  0.1307,  0.1379, -0.3578]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1885, -0.1178, -0.0504,  0.1024,  0.2263]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1648,  0.0705,  0.4058, -0.3886,  0.2706]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4065, -0.1775,  0.2763, -0.3084,  0.3118]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3068, -0.1734, -0.0695,  0.1900, -0.3576]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2284,  0.4009,  0.1554,  0.0350, -0.0347]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1145,  0.2630,  0.2100, -0.0999,  0.0928]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3810, -0.3643, -0.1400, -0.4007,  0.0793]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1366, -0.4117,  0.1492, -0.2236,  0.1135]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0018,  0.3051, -0.1221, -0.4084, -0.4418]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0079,  0.2997, -0.2608, -0.1507, -0.4102]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0049,  0.2839, -0.1988,  0.0841,  0.2992]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3651, -0.2368,  0.1212,  0.1791,  0.3103]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3438, -0.2091, -0.3583, -0.2573,  0.1548]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1765,  0.1218, -0.3231, -0.0805, -0.4184]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4394,  0.3088,  0.1700,  0.3296,  0.0120]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0740,  0.3588,  0.1995,  0.3592,  0.1206]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3299,  0.1729,  0.2140,  0.3351,  0.0824]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0415,  0.2121, -0.2586,  0.3189, -0.4222]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3640, -0.1603,  0.2147, -0.2236, -0.4420]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4412,  0.0095, -0.2948, -0.3130,  0.4156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1267, -0.0857,  0.1559, -0.2929,  0.1141]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2591, -0.1554, -0.0798,  0.0440,  0.0130]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0334, -0.0144, -0.0484,  0.3172, -0.4251]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2660,  0.3863,  0.4029, -0.2248, -0.0729]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3600,  0.3042, -0.3959,  0.3477,  0.1335]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4221,  0.0230, -0.0177, -0.1560, -0.2474]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0295, -0.1039, -0.2645, -0.0726,  0.3275]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4067, -0.1745,  0.1674,  0.1973, -0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0114,  0.3134, -0.0557, -0.2333, -0.4029]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1616,  0.0405,  0.3506, -0.0669,  0.2220]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0945, -0.2852, -0.2434, -0.4294,  0.1091]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2862,  0.1853,  0.3085,  0.0918,  0.3011]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1491,  0.4085,  0.3071, -0.1849,  0.4485]]]], device='cuda:0')),\n",
       "             ('g_enc.feature.0.bias',\n",
       "              tensor([-0.1477, -0.3684, -0.3947, -0.1904, -0.0816, -0.0303,  0.0349, -0.3338,\n",
       "                       0.3376,  0.3976, -0.0474, -0.3887,  0.3759, -0.2293,  0.0182,  0.0628,\n",
       "                       0.1313, -0.3558,  0.1328, -0.1023, -0.2243, -0.3768,  0.4086, -0.0184,\n",
       "                      -0.1577, -0.2619,  0.0651, -0.4123,  0.3957,  0.1217,  0.0506, -0.0693,\n",
       "                       0.4490,  0.2437,  0.1696, -0.3171,  0.1209,  0.1661,  0.3119, -0.2030,\n",
       "                      -0.1905,  0.3087,  0.3754,  0.0517,  0.0664, -0.1764, -0.2630, -0.0043,\n",
       "                      -0.3837, -0.3562], device='cuda:0')),\n",
       "             ('g_enc.feature.3.weight',\n",
       "              tensor([[[[-5.6970e-02, -2.8644e-02, -3.3069e-02,  4.3725e-02,  4.9172e-02]],\n",
       "              \n",
       "                       [[-3.4846e-02,  4.9842e-02,  9.9257e-03,  5.1838e-02, -5.6172e-02]],\n",
       "              \n",
       "                       [[-1.2682e-02, -2.8760e-02,  4.0498e-02, -3.2249e-02, -6.8173e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5570e-02, -9.0264e-03, -1.3444e-02, -4.1927e-03,  4.0033e-02]],\n",
       "              \n",
       "                       [[ 3.1571e-02, -2.7755e-02, -2.9194e-02, -3.0868e-02, -5.2669e-02]],\n",
       "              \n",
       "                       [[-1.2037e-02, -4.6932e-02,  5.5031e-02,  5.0898e-02,  3.1190e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6902e-02, -3.9082e-02,  1.4167e-02, -2.8046e-03,  2.1995e-02]],\n",
       "              \n",
       "                       [[ 4.6977e-02, -6.3344e-02,  4.7671e-02, -2.3797e-02, -1.7088e-02]],\n",
       "              \n",
       "                       [[ 1.0458e-02, -1.7462e-02,  4.5681e-02, -3.8117e-02,  3.2824e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5756e-02, -2.9135e-02, -3.5134e-02,  2.3994e-02, -3.1073e-02]],\n",
       "              \n",
       "                       [[-5.7912e-02,  1.2377e-02,  4.8765e-02, -4.1167e-02,  8.3328e-03]],\n",
       "              \n",
       "                       [[-4.1588e-03,  2.2645e-03,  3.0598e-02, -9.7991e-03,  1.9714e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0421e-02,  4.6126e-02,  3.6441e-02, -3.6895e-02, -3.6347e-02]],\n",
       "              \n",
       "                       [[ 1.2338e-02, -1.4299e-02,  3.4913e-02,  3.5233e-02,  3.2581e-02]],\n",
       "              \n",
       "                       [[ 2.9281e-02, -1.6127e-02,  5.3975e-02, -5.4758e-02, -4.4659e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0434e-02,  1.3402e-02, -5.6507e-02,  3.3459e-02, -1.0550e-02]],\n",
       "              \n",
       "                       [[-4.3563e-02,  3.8817e-02,  5.3813e-02,  1.7353e-02,  2.0152e-02]],\n",
       "              \n",
       "                       [[ 4.2673e-03, -2.8786e-02,  1.5638e-02,  6.3425e-03,  4.0672e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-9.7496e-03,  1.3613e-02, -1.8995e-02, -6.3482e-02, -2.4450e-02]],\n",
       "              \n",
       "                       [[ 3.9330e-02, -1.3251e-02,  4.9964e-02, -2.5538e-02,  5.4399e-02]],\n",
       "              \n",
       "                       [[ 5.0980e-02, -1.3587e-02, -4.2641e-02, -3.2036e-02, -5.1677e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3594e-02,  3.2573e-02, -7.4740e-04, -5.7441e-02, -2.0633e-02]],\n",
       "              \n",
       "                       [[-2.8226e-02,  2.3261e-02,  5.5244e-02,  3.9702e-02, -5.7269e-02]],\n",
       "              \n",
       "                       [[-3.0028e-02, -1.8146e-02, -4.4492e-02,  3.2015e-02,  4.8435e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7292e-02,  7.5114e-03,  3.6079e-02,  3.5636e-02, -5.4767e-02]],\n",
       "              \n",
       "                       [[ 1.7267e-02,  2.9121e-02,  1.8158e-02, -3.8322e-02, -2.2351e-02]],\n",
       "              \n",
       "                       [[ 5.8851e-02, -5.6647e-02,  3.6137e-02, -3.6264e-03, -7.3809e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.5627e-02,  1.7215e-05, -1.3451e-02, -2.3554e-02, -1.3980e-03]],\n",
       "              \n",
       "                       [[ 5.4976e-02,  6.0332e-03,  2.3704e-02,  2.1818e-02,  3.5257e-02]],\n",
       "              \n",
       "                       [[ 6.6652e-02,  1.8110e-02,  5.7210e-02,  4.9419e-02, -2.3964e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7537e-02, -1.1601e-03, -3.9208e-02, -2.8837e-02,  2.4603e-02]],\n",
       "              \n",
       "                       [[-4.4615e-03,  6.3201e-02,  2.1222e-02, -4.5004e-02, -2.8019e-02]],\n",
       "              \n",
       "                       [[-3.7857e-02,  5.7782e-02, -3.2460e-02, -1.3630e-02,  1.1405e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.2682e-02, -4.4200e-03, -8.3983e-03,  4.1317e-03,  3.2947e-02]],\n",
       "              \n",
       "                       [[-4.3529e-02,  4.6463e-03,  1.3057e-02,  3.4903e-02, -3.8915e-02]],\n",
       "              \n",
       "                       [[ 8.0652e-03,  4.9561e-02, -5.6152e-02,  2.9179e-02, -3.8453e-02]]]],\n",
       "                     device='cuda:0')),\n",
       "             ('g_enc.feature.3.bias',\n",
       "              tensor([ 0.0086, -0.0078,  0.0536, -0.0419, -0.0102, -0.0154,  0.0097, -0.0163,\n",
       "                       0.0287, -0.0006,  0.0527,  0.0122,  0.0130,  0.0337, -0.0450, -0.0575,\n",
       "                      -0.0555, -0.0598,  0.0611,  0.0254,  0.0414,  0.0265,  0.0269, -0.0484,\n",
       "                      -0.0536,  0.0063, -0.0537, -0.0101, -0.0478, -0.0435, -0.0334,  0.0174,\n",
       "                       0.0375,  0.0342, -0.0585,  0.0530,  0.0151,  0.0568,  0.0198,  0.0236],\n",
       "                     device='cuda:0')),\n",
       "             ('g_enc.feature.6.weight', tensor([[[[ 0.0098, -0.0200, -0.0147]],\n",
       "              \n",
       "                       [[-0.0393,  0.0256,  0.0051]],\n",
       "              \n",
       "                       [[ 0.0829,  0.0345, -0.0094]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0102, -0.0418,  0.0123]],\n",
       "              \n",
       "                       [[ 0.0431, -0.0093, -0.0285]],\n",
       "              \n",
       "                       [[ 0.0380, -0.0401,  0.0431]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0069, -0.0738, -0.0744]],\n",
       "              \n",
       "                       [[-0.0720,  0.0444, -0.0378]],\n",
       "              \n",
       "                       [[ 0.0273,  0.0709, -0.0595]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0338, -0.0411,  0.0516]],\n",
       "              \n",
       "                       [[-0.0620,  0.0120,  0.0150]],\n",
       "              \n",
       "                       [[ 0.0632,  0.0330,  0.0391]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0372,  0.0881,  0.0810]],\n",
       "              \n",
       "                       [[ 0.0202,  0.0684,  0.0267]],\n",
       "              \n",
       "                       [[ 0.0096,  0.0473,  0.0428]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0332, -0.0395,  0.0620]],\n",
       "              \n",
       "                       [[ 0.0013,  0.0619, -0.0184]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0860, -0.0847]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0092,  0.0865,  0.0357]],\n",
       "              \n",
       "                       [[-0.0852,  0.0632,  0.0878]],\n",
       "              \n",
       "                       [[-0.0294, -0.0833, -0.0381]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0050, -0.0013,  0.0627]],\n",
       "              \n",
       "                       [[-0.0133,  0.0679,  0.0275]],\n",
       "              \n",
       "                       [[-0.0631,  0.0531, -0.0499]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0579, -0.0246, -0.0200]],\n",
       "              \n",
       "                       [[-0.0535,  0.0556,  0.0408]],\n",
       "              \n",
       "                       [[-0.0811,  0.0206, -0.0068]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0122,  0.0612,  0.0484]],\n",
       "              \n",
       "                       [[-0.0670,  0.0486, -0.0554]],\n",
       "              \n",
       "                       [[ 0.0404,  0.0661,  0.0880]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0082,  0.0110, -0.0700]],\n",
       "              \n",
       "                       [[ 0.0874,  0.0898,  0.0036]],\n",
       "              \n",
       "                       [[ 0.0154, -0.0845, -0.0595]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0392,  0.0118,  0.0612]],\n",
       "              \n",
       "                       [[-0.0026, -0.0270, -0.0629]],\n",
       "              \n",
       "                       [[ 0.0216,  0.0293,  0.0613]]]], device='cuda:0')),\n",
       "             ('g_enc.feature.6.bias',\n",
       "              tensor([-0.0308,  0.0745, -0.0616,  0.0248,  0.0537, -0.0114, -0.0107,  0.0175,\n",
       "                      -0.0033, -0.0179, -0.0846, -0.0200,  0.0212,  0.0901, -0.0011, -0.0471,\n",
       "                       0.0060,  0.0108, -0.0815, -0.0107], device='cuda:0')),\n",
       "             ('g_enc.feature.10.weight',\n",
       "              tensor([[-0.0031,  0.0033, -0.0147,  ..., -0.0013,  0.0025,  0.0089],\n",
       "                      [-0.0033, -0.0133, -0.0124,  ...,  0.0100,  0.0128, -0.0037],\n",
       "                      [ 0.0118,  0.0141,  0.0093,  ...,  0.0025, -0.0063, -0.0074],\n",
       "                      ...,\n",
       "                      [ 0.0093, -0.0091, -0.0092,  ..., -0.0073,  0.0018, -0.0066],\n",
       "                      [-0.0112,  0.0070, -0.0046,  ...,  0.0003,  0.0129, -0.0082],\n",
       "                      [ 0.0084, -0.0037, -0.0069,  ...,  0.0029,  0.0025, -0.0138]],\n",
       "                     device='cuda:0')),\n",
       "             ('g_enc.feature.10.bias',\n",
       "              tensor([-0.0047, -0.0052,  0.0048,  ..., -0.0046, -0.0082, -0.0123],\n",
       "                     device='cuda:0')),\n",
       "             ('c_enc.gru.weight_ih_l0',\n",
       "              tensor([[-0.0470, -0.0540,  0.0694,  ...,  0.0340, -0.0503, -0.0024],\n",
       "                      [ 0.0304, -0.0246,  0.0002,  ...,  0.0409,  0.0163,  0.0133],\n",
       "                      [ 0.0350,  0.0653, -0.0045,  ..., -0.0570, -0.0439,  0.0548],\n",
       "                      ...,\n",
       "                      [ 0.0398, -0.0593,  0.0712,  ...,  0.0184, -0.0541,  0.0479],\n",
       "                      [ 0.0559,  0.0543, -0.0281,  ...,  0.0205, -0.0069, -0.0271],\n",
       "                      [-0.0016, -0.0188,  0.0564,  ...,  0.0037, -0.0308, -0.0492]],\n",
       "                     device='cuda:0')),\n",
       "             ('c_enc.gru.weight_hh_l0',\n",
       "              tensor([[ 0.0077,  0.0011, -0.0036,  ...,  0.0194, -0.0612, -0.0239],\n",
       "                      [ 0.0286,  0.0652, -0.0547,  ..., -0.0106, -0.0230, -0.0173],\n",
       "                      [-0.0391,  0.0495, -0.0347,  ..., -0.0132,  0.0593,  0.0333],\n",
       "                      ...,\n",
       "                      [ 0.0147,  0.0287,  0.0526,  ...,  0.0002, -0.0295, -0.0545],\n",
       "                      [ 0.0156, -0.0620, -0.0095,  ..., -0.0129, -0.0223,  0.0273],\n",
       "                      [ 0.0591,  0.0026, -0.0440,  ..., -0.0553,  0.0023, -0.0455]],\n",
       "                     device='cuda:0')),\n",
       "             ('c_enc.gru.bias_ih_l0',\n",
       "              tensor([-5.2470e-02, -3.2725e-02, -2.7403e-02,  6.6389e-02,  6.8827e-02,\n",
       "                       6.7635e-02, -1.7823e-02,  1.5399e-02, -1.7077e-02, -2.6432e-02,\n",
       "                       5.1831e-02, -5.4686e-02, -1.2661e-02, -6.8634e-02,  6.4810e-02,\n",
       "                      -3.2413e-02, -3.5786e-02,  2.3816e-02, -6.4782e-02, -7.0306e-02,\n",
       "                      -4.1577e-02, -2.9088e-02,  2.3633e-02,  5.2527e-02,  6.2584e-03,\n",
       "                      -6.1608e-02, -1.2253e-02,  1.8135e-02, -3.8706e-02, -4.1745e-02,\n",
       "                       2.4738e-02,  5.7593e-03, -6.5259e-02, -4.4794e-02, -6.6172e-02,\n",
       "                       3.6528e-02, -4.8245e-02, -4.0908e-02, -3.9986e-02, -9.4078e-03,\n",
       "                      -2.3925e-02, -3.1304e-02, -4.3281e-02,  5.2278e-02, -1.3224e-03,\n",
       "                      -6.4958e-02,  4.5027e-02, -1.3129e-02,  2.2940e-02, -2.2005e-02,\n",
       "                      -2.2871e-02,  6.4830e-03,  2.6478e-04,  6.0741e-02,  4.2633e-02,\n",
       "                       1.8206e-02,  1.6214e-02, -4.6208e-02, -5.6568e-02,  3.9009e-02,\n",
       "                       1.8271e-02, -5.9276e-02, -3.0492e-02,  5.4075e-02,  4.2684e-02,\n",
       "                       3.4778e-02, -6.9691e-03,  3.8619e-02,  1.6905e-02, -4.6848e-02,\n",
       "                      -5.7252e-02, -1.5504e-02,  6.2112e-02, -4.6981e-02, -5.5568e-02,\n",
       "                       8.7971e-03,  4.3712e-02,  7.7103e-04, -1.1855e-02, -4.1963e-02,\n",
       "                       4.2522e-02,  2.8287e-02,  6.0042e-02,  1.9193e-02, -6.2805e-02,\n",
       "                      -6.1627e-02,  6.3791e-02, -3.8940e-02,  6.7351e-02, -6.7411e-02,\n",
       "                       1.2453e-02,  8.5605e-04,  5.9036e-02, -1.1156e-02,  5.2838e-02,\n",
       "                      -4.2781e-02, -2.1190e-02, -6.6339e-02,  7.7209e-03, -1.4350e-02,\n",
       "                       5.2653e-02, -2.6784e-02, -3.8287e-02, -1.5022e-02,  6.3238e-02,\n",
       "                       5.1675e-02, -6.1659e-02, -4.0263e-02, -5.1637e-02, -6.4015e-02,\n",
       "                       3.3249e-02, -5.4284e-02,  2.8100e-02,  1.0236e-02,  3.2539e-02,\n",
       "                       5.4081e-02, -3.2101e-02,  6.5098e-02, -3.9024e-02, -5.5309e-02,\n",
       "                      -2.0565e-02,  9.0756e-03, -3.3531e-02, -5.3922e-02, -6.8829e-02,\n",
       "                       6.1332e-02,  1.2792e-02, -5.9367e-02,  2.4558e-02, -5.8020e-02,\n",
       "                       4.5895e-02,  6.2382e-02,  1.1597e-02,  1.5308e-02,  1.4648e-02,\n",
       "                       5.6684e-02, -5.5035e-03,  1.6162e-02,  4.5150e-02,  6.3012e-02,\n",
       "                      -5.2865e-02, -2.8256e-02,  6.5255e-02, -2.0605e-02, -3.8779e-02,\n",
       "                       1.0450e-02, -1.1882e-03,  5.1013e-02, -6.0439e-02, -1.6452e-03,\n",
       "                       6.9001e-02, -5.0074e-02, -1.2569e-02, -3.9316e-02,  4.7757e-02,\n",
       "                      -9.8141e-03,  1.2235e-02, -2.6656e-02,  2.6081e-02,  4.8587e-02,\n",
       "                      -3.6432e-02, -2.9244e-02, -4.1032e-02,  1.6763e-02,  3.6978e-02,\n",
       "                       1.3796e-02, -5.4168e-02, -2.7569e-02, -1.7130e-02,  5.4536e-02,\n",
       "                      -1.4750e-02,  4.8048e-02,  2.0448e-02,  7.0053e-02,  5.7969e-02,\n",
       "                      -4.9558e-02, -2.3386e-02, -4.8594e-02,  6.1915e-02,  1.0814e-02,\n",
       "                      -5.4890e-02, -3.1139e-02, -2.1812e-03, -5.5937e-02, -2.9917e-02,\n",
       "                      -2.9849e-02, -2.9530e-02,  2.5544e-02,  6.1596e-02,  4.2866e-02,\n",
       "                       2.9798e-02,  2.1531e-02,  6.6720e-02,  6.7475e-02,  4.0685e-02,\n",
       "                       4.1894e-02,  1.3970e-02, -6.4342e-02,  3.2124e-02,  4.8225e-02,\n",
       "                      -5.4980e-02,  3.0776e-02, -1.6347e-03, -6.4279e-02, -3.8538e-02,\n",
       "                      -7.5154e-02,  6.0204e-02,  2.6383e-03, -2.5337e-02, -5.1198e-02,\n",
       "                       4.8051e-02,  2.1857e-02,  4.1401e-02,  3.0699e-02,  3.6152e-02,\n",
       "                      -4.9762e-02,  4.3735e-03, -3.4153e-02,  1.1111e-02, -1.3878e-02,\n",
       "                       5.1955e-02, -1.0200e-03, -4.2262e-02,  2.7771e-02,  5.5557e-02,\n",
       "                       6.4391e-02,  4.3018e-02,  3.0556e-02, -6.9190e-03, -5.1559e-02,\n",
       "                       3.1392e-03,  1.4108e-02, -2.1458e-02, -1.0309e-02,  5.0987e-02,\n",
       "                      -1.7523e-02, -7.2967e-02,  1.7545e-02, -8.2012e-03,  5.5487e-02,\n",
       "                       9.5740e-03,  3.7901e-02,  3.5534e-02, -2.1174e-02, -3.4137e-02,\n",
       "                      -5.8933e-02,  4.2229e-02,  6.4276e-03, -1.2687e-02,  5.3226e-02,\n",
       "                       1.0482e-02, -6.4370e-02, -5.5945e-02,  1.6039e-02, -2.6631e-03,\n",
       "                       1.8679e-02, -6.5346e-02, -3.0842e-02,  2.5393e-03,  2.6969e-03,\n",
       "                      -3.1881e-02, -5.1574e-02, -3.9575e-02,  5.7304e-02, -6.8547e-02,\n",
       "                      -2.4240e-02, -3.3671e-02, -6.1243e-02,  6.3638e-02,  6.2387e-02,\n",
       "                      -3.3937e-02, -4.4562e-02,  4.4828e-02, -2.5792e-02, -4.1758e-02,\n",
       "                      -3.4550e-02, -2.3954e-02, -3.4350e-02, -3.4705e-03, -5.7853e-03,\n",
       "                       3.9958e-02,  5.9785e-02, -2.8657e-02, -6.6664e-02, -4.0445e-02,\n",
       "                       6.5609e-02, -6.0274e-02, -3.1868e-02, -1.4445e-02,  4.6173e-02,\n",
       "                       4.6725e-02,  5.3410e-02, -5.3647e-02,  2.6142e-02, -2.0793e-02,\n",
       "                       1.9866e-02, -3.3402e-03,  6.2953e-02,  3.4177e-02, -3.5761e-02,\n",
       "                      -5.9965e-02, -3.2261e-02, -6.1017e-02,  1.2113e-02,  1.9523e-02,\n",
       "                       6.5566e-02,  3.7955e-02,  1.1890e-02, -3.7066e-02,  4.9203e-02,\n",
       "                       4.6961e-02, -4.3736e-02, -2.7637e-02, -1.9705e-02,  5.5882e-02,\n",
       "                       1.4448e-02,  5.6863e-02, -6.6179e-02,  4.0852e-02, -3.4892e-02,\n",
       "                      -6.3104e-02, -6.2438e-02, -6.2950e-03, -3.4290e-02,  4.4215e-02,\n",
       "                       5.4729e-02, -4.0100e-02, -1.6993e-02,  3.9060e-02, -3.2582e-02,\n",
       "                       7.0262e-02, -7.7672e-03,  6.3411e-02, -3.7114e-02,  5.0740e-02,\n",
       "                       1.2811e-02,  4.7738e-02, -3.1073e-02,  3.6074e-02, -1.6421e-02,\n",
       "                       5.4923e-02,  4.5152e-02, -4.3825e-03,  1.6323e-02,  8.7676e-03,\n",
       "                      -2.5969e-02,  3.5242e-02,  4.2038e-02, -2.0241e-02,  4.2759e-02,\n",
       "                       6.0610e-02,  5.2226e-02,  1.5661e-02, -5.0803e-02,  6.3353e-02,\n",
       "                      -7.6013e-03, -1.0739e-02,  1.6084e-02,  5.6318e-02, -4.1543e-02,\n",
       "                      -1.1321e-02,  4.9149e-02,  5.9784e-02,  3.4144e-02,  5.7051e-02,\n",
       "                       4.5549e-02, -6.5577e-05,  1.2476e-02, -2.6247e-02, -5.1510e-02,\n",
       "                      -1.4542e-02, -4.6549e-03,  2.0251e-02,  2.4814e-02,  6.7766e-02,\n",
       "                      -1.9921e-02, -2.0499e-02, -6.0325e-02,  6.2203e-02,  1.5387e-02,\n",
       "                      -5.7168e-03,  1.7789e-02, -3.7137e-02,  6.4628e-02,  9.5491e-03,\n",
       "                       1.0309e-02, -3.5551e-02, -1.1180e-02,  2.6136e-02, -4.1984e-02,\n",
       "                      -5.7094e-02, -3.0900e-02,  2.4115e-02, -1.0135e-03, -4.6600e-02,\n",
       "                      -5.8242e-02,  1.0290e-02,  4.7685e-02,  6.1614e-02, -3.4595e-02,\n",
       "                       5.2014e-02,  1.0645e-02,  4.8059e-02, -6.7895e-02, -2.3903e-02,\n",
       "                      -5.4475e-02, -2.2899e-02, -5.5982e-02,  1.0258e-02,  6.3503e-02,\n",
       "                      -7.7244e-03,  2.4613e-02, -4.6857e-02,  2.9814e-02,  1.8281e-02,\n",
       "                      -6.1705e-02, -1.4431e-02,  6.4908e-02,  1.7778e-03,  1.5074e-03,\n",
       "                      -2.4816e-02, -6.3948e-02,  2.0023e-02,  2.0756e-02, -6.0413e-02,\n",
       "                       5.3561e-02,  5.9382e-02,  5.4710e-03,  6.4783e-02,  5.5829e-02,\n",
       "                      -2.1088e-03, -1.3122e-03, -6.8482e-02,  2.0754e-02,  1.1338e-02,\n",
       "                      -1.1652e-02, -6.6170e-02, -4.3843e-02, -5.5608e-02,  3.8574e-02,\n",
       "                       5.2888e-02, -1.2393e-03,  6.2238e-02, -3.4741e-03,  3.6755e-02,\n",
       "                      -6.6475e-02, -3.3838e-02,  6.3120e-02, -4.4378e-02,  1.8317e-02,\n",
       "                      -6.6895e-02, -1.3050e-02, -6.4402e-02,  6.2766e-02, -4.7612e-02,\n",
       "                      -5.4663e-02,  5.9207e-02,  8.6097e-03, -6.4215e-02,  4.8605e-03,\n",
       "                      -1.0484e-02,  3.6579e-02, -3.0640e-02, -3.2530e-02, -6.1728e-02,\n",
       "                      -6.2062e-02, -2.9593e-02,  1.6725e-02, -4.5733e-02,  1.1009e-02,\n",
       "                       3.0768e-02, -6.4246e-02,  6.8181e-02, -3.7123e-02,  5.7139e-02,\n",
       "                      -5.9049e-02, -9.8098e-03, -6.7856e-02,  1.1238e-02, -1.6686e-02,\n",
       "                      -1.2365e-03,  4.7439e-02, -3.3268e-02, -4.0303e-02, -3.9941e-02,\n",
       "                       7.0469e-03,  1.2416e-04, -3.7669e-02, -3.2025e-03, -1.0283e-02,\n",
       "                       4.6062e-02, -6.5107e-02,  2.0299e-02, -1.1944e-03,  2.8433e-02,\n",
       "                       2.2364e-02, -8.6334e-03,  4.4947e-02,  1.7440e-02, -6.9452e-02,\n",
       "                      -3.5019e-02,  6.7649e-02,  6.2877e-02, -6.9388e-02, -4.7311e-03,\n",
       "                       8.5668e-03, -7.1768e-03,  1.7521e-02,  5.8603e-02, -5.2853e-02,\n",
       "                       7.1802e-02,  4.0778e-02, -3.5137e-02,  6.8028e-02,  7.3353e-03,\n",
       "                       2.0861e-03, -5.7047e-02,  7.1578e-03, -4.6350e-02, -1.0990e-02,\n",
       "                       4.7299e-02, -5.0120e-02,  3.4241e-02,  5.4971e-02, -3.4589e-02,\n",
       "                      -8.8667e-04,  1.9379e-02,  3.2772e-02,  5.5942e-02, -4.4793e-02,\n",
       "                      -2.5775e-02, -1.0693e-02,  3.4478e-03,  4.6735e-02,  3.2011e-03,\n",
       "                      -1.2373e-02,  3.8136e-02,  1.0783e-02,  6.0079e-02, -2.8451e-02,\n",
       "                       2.7097e-02, -3.8220e-02, -4.1727e-02, -1.1610e-02,  1.7410e-02,\n",
       "                       1.8133e-02,  5.1373e-02, -4.3358e-02,  5.5777e-03, -5.1682e-02,\n",
       "                      -5.2023e-02, -1.2327e-02,  6.6526e-02, -4.3541e-02, -6.8578e-02,\n",
       "                       3.8391e-02,  5.4989e-02,  6.5218e-02, -5.9657e-02,  5.4553e-02,\n",
       "                      -1.5311e-02,  1.1195e-02,  5.0596e-02, -6.3457e-02, -5.7131e-02,\n",
       "                       1.3069e-02,  3.5931e-02,  3.4502e-02, -3.1261e-02,  3.3595e-02,\n",
       "                       3.3377e-02, -5.5268e-02,  1.3238e-02,  2.2831e-03,  2.2350e-02,\n",
       "                      -3.5645e-02,  5.1078e-02,  1.2203e-02, -7.9712e-03, -4.8620e-02,\n",
       "                      -2.5403e-02,  1.3606e-02, -5.3458e-02, -1.9706e-02,  2.6824e-02,\n",
       "                      -1.3961e-02, -3.4255e-02,  6.7776e-02,  6.6488e-03,  5.7480e-03,\n",
       "                      -9.7397e-03, -4.3003e-02,  1.8795e-02,  5.1674e-02,  5.2382e-03,\n",
       "                       3.6561e-02,  3.1596e-02,  2.3476e-03, -7.7600e-03,  2.7666e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('c_enc.gru.bias_hh_l0',\n",
       "              tensor([ 0.0226, -0.0412, -0.0477,  0.0366,  0.0165, -0.0261, -0.0221,  0.0516,\n",
       "                      -0.0486,  0.0513,  0.0393, -0.0112,  0.0491, -0.0557, -0.0050,  0.0527,\n",
       "                       0.0231,  0.0307, -0.0417,  0.0253, -0.0223,  0.0180,  0.0322, -0.0106,\n",
       "                       0.0037,  0.0618, -0.0146, -0.0163, -0.0562, -0.0209, -0.0556, -0.0386,\n",
       "                      -0.0270, -0.0104, -0.0076, -0.0653,  0.0512,  0.0702, -0.0205,  0.0555,\n",
       "                       0.0438,  0.0356, -0.0371, -0.0296,  0.0023, -0.0157,  0.0570, -0.0029,\n",
       "                      -0.0238, -0.0438,  0.0253, -0.0157, -0.0444, -0.0356,  0.0485,  0.0054,\n",
       "                       0.0349, -0.0436,  0.0453,  0.0576,  0.0602,  0.0068, -0.0406,  0.0392,\n",
       "                       0.0067,  0.0122,  0.0008,  0.0328,  0.0460, -0.0652, -0.0097, -0.0609,\n",
       "                       0.0419,  0.0640, -0.0717,  0.0513, -0.0636,  0.0437,  0.0640,  0.0099,\n",
       "                      -0.0004, -0.0678, -0.0359, -0.0194, -0.0128,  0.0120, -0.0295,  0.0640,\n",
       "                      -0.0172,  0.0001, -0.0667,  0.0607, -0.0331,  0.0352, -0.0108, -0.0532,\n",
       "                       0.0335,  0.0140, -0.0327,  0.0052,  0.0671, -0.0315,  0.0658, -0.0388,\n",
       "                      -0.0259, -0.0641, -0.0112, -0.0141,  0.0474, -0.0517, -0.0496, -0.0055,\n",
       "                       0.0460,  0.0644,  0.0465, -0.0440, -0.0029, -0.0151,  0.0629, -0.0093,\n",
       "                      -0.0339, -0.0342,  0.0306, -0.0204,  0.0485,  0.0067,  0.0365,  0.0230,\n",
       "                       0.0586, -0.0500, -0.0594, -0.0376,  0.0525,  0.0002, -0.0067, -0.0224,\n",
       "                      -0.0650, -0.0036, -0.0296,  0.0338,  0.0220,  0.0008, -0.0526, -0.0302,\n",
       "                      -0.0377, -0.0473, -0.0234, -0.0615, -0.0339,  0.0271,  0.0380, -0.0044,\n",
       "                       0.0228, -0.0547,  0.0565,  0.0264, -0.0319, -0.0092,  0.0350,  0.0470,\n",
       "                      -0.0404,  0.0330,  0.0049, -0.0340, -0.0432, -0.0640,  0.0630,  0.0176,\n",
       "                      -0.0467, -0.0646, -0.0188, -0.0563,  0.0546, -0.0147, -0.0198, -0.0421,\n",
       "                      -0.0408, -0.0670,  0.0555,  0.0594,  0.0328, -0.0229,  0.0018,  0.0194,\n",
       "                       0.0451,  0.0469,  0.0110, -0.0043, -0.0185,  0.0275,  0.0258, -0.0604,\n",
       "                       0.0334,  0.0310,  0.0486, -0.0425,  0.0499, -0.0486, -0.0223,  0.0481,\n",
       "                       0.0585,  0.0272, -0.0011,  0.0393,  0.0355, -0.0714,  0.0245, -0.0104,\n",
       "                      -0.0180,  0.0330, -0.0486, -0.0022,  0.0534, -0.0582, -0.0255,  0.0005,\n",
       "                       0.0241, -0.0622, -0.0031, -0.0552,  0.0642,  0.0246,  0.0607,  0.0152,\n",
       "                       0.0628,  0.0144,  0.0313, -0.0662, -0.0313,  0.0183,  0.0108,  0.0182,\n",
       "                      -0.0161,  0.0476, -0.0620, -0.0191,  0.0162,  0.0618,  0.0306,  0.0677,\n",
       "                       0.0219,  0.0456, -0.0396, -0.0061,  0.0247, -0.0511,  0.0455, -0.0128,\n",
       "                       0.0489, -0.0151, -0.0634, -0.0398, -0.0619, -0.0653, -0.0045,  0.0308,\n",
       "                       0.0388,  0.0357,  0.0002,  0.0360, -0.0694, -0.0216, -0.0215,  0.0284,\n",
       "                      -0.0145,  0.0600,  0.0217, -0.0051, -0.0253, -0.0025, -0.0027,  0.0447,\n",
       "                       0.0418,  0.0093, -0.0393, -0.0407,  0.0067, -0.0213,  0.0376,  0.0275,\n",
       "                       0.0248, -0.0209,  0.0407,  0.0035, -0.0747,  0.0648, -0.0502, -0.0693,\n",
       "                       0.0383,  0.0551, -0.0104, -0.0427,  0.0250,  0.0666, -0.0001, -0.0106,\n",
       "                       0.0134,  0.0030,  0.0586, -0.0597, -0.0408,  0.0048, -0.0411, -0.0077,\n",
       "                      -0.0462, -0.0501,  0.0522, -0.0512, -0.0472, -0.0004,  0.0121, -0.0553,\n",
       "                       0.0329,  0.0248,  0.0313, -0.0054,  0.0510, -0.0425, -0.0561,  0.0605,\n",
       "                       0.0671, -0.0492, -0.0258, -0.0595,  0.0307,  0.0305,  0.0153,  0.0022,\n",
       "                       0.0512, -0.0199, -0.0465,  0.0297,  0.0642,  0.0185,  0.0086, -0.0584,\n",
       "                       0.0178,  0.0083,  0.0385, -0.0602, -0.0232,  0.0701,  0.0238,  0.0526,\n",
       "                      -0.0420,  0.0571, -0.0091, -0.0182, -0.0530,  0.0442, -0.0293, -0.0016,\n",
       "                      -0.0626, -0.0244, -0.0116, -0.0518, -0.0605, -0.0425, -0.0190, -0.0263,\n",
       "                       0.0098, -0.0124,  0.0338,  0.0200,  0.0649, -0.0041, -0.0247,  0.0002,\n",
       "                       0.0317, -0.0286, -0.0027,  0.0647, -0.0445,  0.0168, -0.0658, -0.0108,\n",
       "                       0.0057, -0.0100, -0.0415,  0.0173, -0.0050, -0.0553,  0.0212,  0.0268,\n",
       "                      -0.0514,  0.0122,  0.0479, -0.0287, -0.0210, -0.0568, -0.0723,  0.0143,\n",
       "                       0.0203,  0.0349, -0.0083,  0.0016, -0.0636, -0.0405,  0.0444, -0.0399,\n",
       "                      -0.0131,  0.0487, -0.0439, -0.0247, -0.0332, -0.0229,  0.0398,  0.0523,\n",
       "                       0.0208,  0.0062,  0.0102,  0.0473,  0.0052, -0.0358,  0.0090,  0.0448,\n",
       "                       0.0035,  0.0513, -0.0458, -0.0442,  0.0078, -0.0285, -0.0147, -0.0403,\n",
       "                      -0.0454,  0.0639,  0.0702, -0.0358, -0.0454, -0.0166,  0.0378,  0.0027,\n",
       "                      -0.0417, -0.0549,  0.0202,  0.0251, -0.0262,  0.0274, -0.0623, -0.0053,\n",
       "                      -0.0259,  0.0218,  0.0018,  0.0497,  0.0157, -0.0298,  0.0574, -0.0320,\n",
       "                       0.0540,  0.0543,  0.0394, -0.0208, -0.0231,  0.0269, -0.0196, -0.0017,\n",
       "                      -0.0495, -0.0231, -0.0545,  0.0109, -0.0142,  0.0625, -0.0052, -0.0086,\n",
       "                       0.0290, -0.0385,  0.0025,  0.0329,  0.0548,  0.0327, -0.0288, -0.0691,\n",
       "                      -0.0435,  0.0438, -0.0599, -0.0250,  0.0146, -0.0121, -0.0478,  0.0696,\n",
       "                       0.0286,  0.0379,  0.0555,  0.0545,  0.0077, -0.0361, -0.0100,  0.0433,\n",
       "                      -0.0573, -0.0232,  0.0037,  0.0293,  0.0152, -0.0406, -0.0430, -0.0503,\n",
       "                      -0.0620, -0.0045,  0.0594,  0.0018, -0.0092, -0.0099,  0.0431,  0.0202,\n",
       "                       0.0069,  0.0588, -0.0530,  0.0209,  0.0644, -0.0415, -0.0510, -0.0116,\n",
       "                       0.0361,  0.0011,  0.0278, -0.0117, -0.0394, -0.0387, -0.0181, -0.0666,\n",
       "                      -0.0114, -0.0680,  0.0123,  0.0050, -0.0635,  0.0415, -0.0206,  0.0156,\n",
       "                       0.0516, -0.0290, -0.0687, -0.0056, -0.0332, -0.0124, -0.0675, -0.0473,\n",
       "                      -0.0526,  0.0258, -0.0050,  0.0059,  0.0030,  0.0030, -0.0272, -0.0253,\n",
       "                      -0.0537,  0.0188, -0.0367,  0.0679, -0.0098, -0.0572, -0.0467,  0.0613,\n",
       "                       0.0258, -0.0398,  0.0329, -0.0407,  0.0208,  0.0186, -0.0106,  0.0070,\n",
       "                      -0.0570,  0.0098,  0.0342, -0.0472,  0.0602, -0.0562,  0.0689, -0.0238,\n",
       "                       0.0271,  0.0159, -0.0646, -0.0158, -0.0270,  0.0429,  0.0006,  0.0114,\n",
       "                       0.0069, -0.0175, -0.0510, -0.0093, -0.0130,  0.0095, -0.0053,  0.0196,\n",
       "                       0.0335, -0.0015,  0.0379, -0.0316,  0.0572, -0.0252, -0.0490, -0.0249,\n",
       "                      -0.0636,  0.0390,  0.0059, -0.0449, -0.0112,  0.0402,  0.0218, -0.0111],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.0.weight',\n",
       "              tensor([[-0.0006, -0.0307, -0.0447,  ...,  0.0071, -0.0412,  0.0440],\n",
       "                      [-0.0033, -0.0556,  0.0122,  ..., -0.0295,  0.0575, -0.0110],\n",
       "                      [-0.0344, -0.0464, -0.0215,  ..., -0.0072,  0.0390, -0.0339],\n",
       "                      ...,\n",
       "                      [ 0.0474,  0.0060, -0.0118,  ...,  0.0459, -0.0649, -0.0289],\n",
       "                      [ 0.0329, -0.0512,  0.0154,  ..., -0.0552,  0.0659, -0.0091],\n",
       "                      [-0.0015, -0.0604,  0.0484,  ...,  0.0200, -0.0387, -0.0211]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.0.bias',\n",
       "              tensor([ 0.0665, -0.0366,  0.0495,  ..., -0.0078,  0.0420,  0.0005],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.1.weight',\n",
       "              tensor([[ 0.0142,  0.0408, -0.0158,  ...,  0.0560, -0.0235,  0.0648],\n",
       "                      [ 0.0544,  0.0162, -0.0518,  ...,  0.0192, -0.0052, -0.0493],\n",
       "                      [-0.0326,  0.0057, -0.0358,  ..., -0.0672, -0.0452,  0.0241],\n",
       "                      ...,\n",
       "                      [ 0.0613,  0.0213, -0.0060,  ..., -0.0499,  0.0524,  0.0396],\n",
       "                      [ 0.0516, -0.0366,  0.0088,  ..., -0.0303, -0.0176, -0.0462],\n",
       "                      [-0.0005,  0.0110,  0.0553,  ..., -0.0097, -0.0340, -0.0114]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.1.bias',\n",
       "              tensor([-0.0226, -0.0558, -0.0220,  ...,  0.0417, -0.0182, -0.0347],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.2.weight',\n",
       "              tensor([[ 0.0174,  0.0336,  0.0083,  ..., -0.0539,  0.0649,  0.0529],\n",
       "                      [ 0.0170,  0.0301,  0.0610,  ..., -0.0663, -0.0599,  0.0630],\n",
       "                      [-0.0349,  0.0091,  0.0031,  ..., -0.0060, -0.0122,  0.0542],\n",
       "                      ...,\n",
       "                      [-0.0376,  0.0684, -0.0627,  ..., -0.0106,  0.0393,  0.0405],\n",
       "                      [-0.0125, -0.0144,  0.0505,  ..., -0.0486,  0.0700,  0.0321],\n",
       "                      [-0.0437, -0.0215,  0.0055,  ..., -0.0165,  0.0683, -0.0512]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.2.bias',\n",
       "              tensor([ 0.0257, -0.0654,  0.0307,  ..., -0.0347, -0.0682, -0.0572],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.3.weight',\n",
       "              tensor([[-0.0686, -0.0117,  0.0636,  ..., -0.0572,  0.0439,  0.0662],\n",
       "                      [-0.0082,  0.0697,  0.0447,  ..., -0.0050,  0.0373, -0.0692],\n",
       "                      [ 0.0476,  0.0262, -0.0032,  ...,  0.0416, -0.0380, -0.0183],\n",
       "                      ...,\n",
       "                      [-0.0134,  0.0664, -0.0033,  ...,  0.0552,  0.0196,  0.0429],\n",
       "                      [-0.0128, -0.0551, -0.0506,  ..., -0.0089,  0.0134, -0.0284],\n",
       "                      [ 0.0043, -0.0584, -0.0069,  ..., -0.0586, -0.0065, -0.0029]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.3.bias',\n",
       "              tensor([ 0.0547,  0.0546, -0.0504,  ...,  0.0673,  0.0207,  0.0083],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.4.weight',\n",
       "              tensor([[ 0.0334,  0.0046, -0.0388,  ...,  0.0090, -0.0181,  0.0536],\n",
       "                      [ 0.0563,  0.0100, -0.0134,  ...,  0.0434,  0.0408,  0.0625],\n",
       "                      [-0.0470,  0.0395, -0.0191,  ..., -0.0037,  0.0297, -0.0112],\n",
       "                      ...,\n",
       "                      [ 0.0025, -0.0123,  0.0038,  ..., -0.0272, -0.0234, -0.0681],\n",
       "                      [ 0.0158,  0.0271, -0.0488,  ..., -0.0268, -0.0362, -0.0593],\n",
       "                      [ 0.0283, -0.0298, -0.0406,  ..., -0.0337,  0.0432, -0.0563]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictor.linears.4.bias',\n",
       "              tensor([-6.1957e-02, -5.1929e-02,  4.0897e-02,  ..., -3.8630e-02,\n",
       "                      -4.5321e-02,  1.6197e-05], device='cuda:0'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "torch.load(os.path.join(result['info']['log_dir'], 'model_100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
