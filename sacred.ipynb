{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sacred Objectからちゃんとデータを取り出す（普通にDone）\n",
    "* Sacred Objectを使って，アーチファクトを取り出す（Artifactは，正直形式がわからないので使わない．_run['info']['log_dir']を記録しておいて，普通にファイルパスで読み取る\n",
    "* 既にやってた実験をSacredの方に入れ込む方法を考える\n",
    "  (これはSacredのUI使う方が多分やりやすい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred_wrap import SacredRecords\n",
    "from sacred_wrap import MongoExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mSacredRecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mongo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquery_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdb_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexact_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COMPLETED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /share/iwasawa/constrastive_predictive_coding/sacred_wrap.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset.K</th>\n",
       "      <th>dataset.L</th>\n",
       "      <th>dataset.name</th>\n",
       "      <th>dataset.test_domain</th>\n",
       "      <th>dataset.validation</th>\n",
       "      <th>db_name</th>\n",
       "      <th>gpu</th>\n",
       "      <th>method.context</th>\n",
       "      <th>method.hidden</th>\n",
       "      <th>method.name</th>\n",
       "      <th>...</th>\n",
       "      <th>valid-loss-3</th>\n",
       "      <th>valid-loss-4</th>\n",
       "      <th>train-accuracy-5</th>\n",
       "      <th>train-accuracy-6</th>\n",
       "      <th>train-loss-5</th>\n",
       "      <th>train-loss-6</th>\n",
       "      <th>valid-accuracy-5</th>\n",
       "      <th>valid-accuracy-6</th>\n",
       "      <th>valid-loss-5</th>\n",
       "      <th>valid-loss-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.45371005819602445, inf, 0.302120764316483, ...</td>\n",
       "      <td>[0.4801474826579744, inf, 0.3308345401151614, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.45319285921075125, 0.3394818873229352, 0.29...</td>\n",
       "      <td>[0.4713144922121005, inf, 0.33573758686808025,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.44412956860932434, inf, inf, 0.265691587532...</td>\n",
       "      <td>[0.472256811843677, inf, inf, 0.29690771668472...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4381232976236127, inf, 0.3113577083091844, ...</td>\n",
       "      <td>[0.4644385041161017, 0.35976594212380325, 0.34...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5482556579465215, 0.40724434940652415, 0.34...</td>\n",
       "      <td>[0.5603910054672848, 0.43406626683744515, 0.36...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>800</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.49599879810755904, 0.3647491203790361, 0.31...</td>\n",
       "      <td>[0.5111820735037327, 0.3894911909645254, 0.341...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>3200</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4101121229204265, 0.32619875771078194, 0.29...</td>\n",
       "      <td>[0.43427001617171546, 0.35239154371348297, 0.3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.46055375615304167, 0.3349308127706701, 0.27...</td>\n",
       "      <td>[0.4711907143619927, 0.3634863597425548, 0.299...</td>\n",
       "      <td>[0.7639180672268907, 0.8484933035714286, 0.881...</td>\n",
       "      <td>[0.7540211397058824, 0.8396303834033614, 0.875...</td>\n",
       "      <td>[0.4873472778987484, 0.35292161788259235, 0.28...</td>\n",
       "      <td>[0.5016939223063093, 0.3733990410295855, 0.297...</td>\n",
       "      <td>[0.7632723721590909, 0.8330522017045454, 0.867...</td>\n",
       "      <td>[0.7551935369318182, 0.8193359375, 0.856844815...</td>\n",
       "      <td>[0.4856484572995793, 0.3809159377759153, 0.322...</td>\n",
       "      <td>[0.5007589523765174, 0.4054652526974678, 0.338...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4579513225365769, 0.34726549177007243, 0.29...</td>\n",
       "      <td>[0.48140101439573546, 0.3625698746605353, 0.32...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4570596878501502, 0.3409600373018872, 0.308...</td>\n",
       "      <td>[0.48127355765212665, 0.3595139943063259, 0.34...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>oppG</td>\n",
       "      <td>S1</td>\n",
       "      <td>ADL4-ADL5</td>\n",
       "      <td>CPC_test</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1600</td>\n",
       "      <td>CPC</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4773834252899343, 0.3525478342040019, 0.303...</td>\n",
       "      <td>[0.4955991137434136, 0.37448755922642624, 0.31...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset.K  dataset.L dataset.name dataset.test_domain dataset.validation  \\\n",
       "0           5         12         oppG                  S1          ADL4-ADL5   \n",
       "1           5         12         oppG                  S1          ADL4-ADL5   \n",
       "2           5         12         oppG                  S1          ADL4-ADL5   \n",
       "3           5         12         oppG                  S1          ADL4-ADL5   \n",
       "4           5         12         oppG                  S1          ADL4-ADL5   \n",
       "5           5         12         oppG                  S1          ADL4-ADL5   \n",
       "6           5         12         oppG                  S1          ADL4-ADL5   \n",
       "7           1         12         oppG                  S1          ADL4-ADL5   \n",
       "8           3         12         oppG                  S1          ADL4-ADL5   \n",
       "9           7         12         oppG                  S1          ADL4-ADL5   \n",
       "10          5          9         oppG                  S1          ADL4-ADL5   \n",
       "11          5         15         oppG                  S1          ADL4-ADL5   \n",
       "12          5         12         oppG                  S1          ADL4-ADL5   \n",
       "\n",
       "     db_name  gpu  method.context  method.hidden method.name  ...  \\\n",
       "0   CPC_test    3             200           1600         CPC  ...   \n",
       "1   CPC_test    2             400           1600         CPC  ...   \n",
       "2   CPC_test    1             800           1600         CPC  ...   \n",
       "3   CPC_test    0            1600           1600         CPC  ...   \n",
       "4   CPC_test    2             200            400         CPC  ...   \n",
       "5   CPC_test    3             200            800         CPC  ...   \n",
       "6   CPC_test    1             200           3200         CPC  ...   \n",
       "7   CPC_test    0             800           1600         CPC  ...   \n",
       "8   CPC_test    0             800           1600         CPC  ...   \n",
       "9   CPC_test    2             800           1600         CPC  ...   \n",
       "10  CPC_test    3             800           1600         CPC  ...   \n",
       "11  CPC_test    1             800           1600         CPC  ...   \n",
       "12  CPC_test    0             800           1600         CPC  ...   \n",
       "\n",
       "                                         valid-loss-3  \\\n",
       "0   [0.45371005819602445, inf, 0.302120764316483, ...   \n",
       "1   [0.45319285921075125, 0.3394818873229352, 0.29...   \n",
       "2   [0.44412956860932434, inf, inf, 0.265691587532...   \n",
       "3   [0.4381232976236127, inf, 0.3113577083091844, ...   \n",
       "4   [0.5482556579465215, 0.40724434940652415, 0.34...   \n",
       "5   [0.49599879810755904, 0.3647491203790361, 0.31...   \n",
       "6   [0.4101121229204265, 0.32619875771078194, 0.29...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.46055375615304167, 0.3349308127706701, 0.27...   \n",
       "10  [0.4579513225365769, 0.34726549177007243, 0.29...   \n",
       "11  [0.4570596878501502, 0.3409600373018872, 0.308...   \n",
       "12  [0.4773834252899343, 0.3525478342040019, 0.303...   \n",
       "\n",
       "                                         valid-loss-4  \\\n",
       "0   [0.4801474826579744, inf, 0.3308345401151614, ...   \n",
       "1   [0.4713144922121005, inf, 0.33573758686808025,...   \n",
       "2   [0.472256811843677, inf, inf, 0.29690771668472...   \n",
       "3   [0.4644385041161017, 0.35976594212380325, 0.34...   \n",
       "4   [0.5603910054672848, 0.43406626683744515, 0.36...   \n",
       "5   [0.5111820735037327, 0.3894911909645254, 0.341...   \n",
       "6   [0.43427001617171546, 0.35239154371348297, 0.3...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.4711907143619927, 0.3634863597425548, 0.299...   \n",
       "10  [0.48140101439573546, 0.3625698746605353, 0.32...   \n",
       "11  [0.48127355765212665, 0.3595139943063259, 0.34...   \n",
       "12  [0.4955991137434136, 0.37448755922642624, 0.31...   \n",
       "\n",
       "                                     train-accuracy-5  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.7639180672268907, 0.8484933035714286, 0.881...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                     train-accuracy-6  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.7540211397058824, 0.8396303834033614, 0.875...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                         train-loss-5  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.4873472778987484, 0.35292161788259235, 0.28...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                         train-loss-6  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.5016939223063093, 0.3733990410295855, 0.297...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                     valid-accuracy-5  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.7632723721590909, 0.8330522017045454, 0.867...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                     valid-accuracy-6  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.7551935369318182, 0.8193359375, 0.856844815...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                         valid-loss-5  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   [0.4856484572995793, 0.3809159377759153, 0.322...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "\n",
       "                                         valid-loss-6  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9   [0.5007589523765174, 0.4054652526974678, 0.338...  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "\n",
       "[13 rows x 47 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = SacredRecords.from_mongo({'method.name': 'CPC', 'seed': 123456}, db_name='CPC_test')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用のスクリプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import OppG\n",
    "from utils import split_dataset\n",
    "\n",
    "\n",
    "def get_dataset(name, validation, test_domain, L, K):\n",
    "    \"\"\"Prepare datasets for train, valid and test with configurations.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    name : str\n",
    "    validation : str or list\n",
    "    test_domain : str or list\n",
    "    L : int\n",
    "    K : int\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    {train/valid}_dataset_{joint/marginal} : torch.Dataset\n",
    "        {train/valid} datasets from {joint/marginal} distributions\n",
    "    \"\"\"\n",
    "    if isinstance(validation, str):\n",
    "        validation = validation.split('-')\n",
    "    all_adls = OppG.get('all_adls')\n",
    "    all_domain = OppG.get('all_domain_key')\n",
    "    train_adls = sorted(list(set(all_adls) - set(validation)))\n",
    "    train_domain = sorted(list(set(all_domain) - set([test_domain])))\n",
    "    train_dataset_joint = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K+L, adl_ids=train_adls)\n",
    "    valid_dataset_joint = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K+L, adl_ids=validation)\n",
    "\n",
    "    # marginal sample come from same datasets for simplicity\n",
    "    # Same train-valid split with joint dataset\n",
    "    train_dataset_marginal = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K, adl_ids=train_adls)\n",
    "    valid_dataset_marginal = OppG(\n",
    "        train_domain, l_sample=30, interval=15, T=K, adl_ids=validation)\n",
    "    test_dataset = OppG(test_domain, l_sample=30, interval=15, T=K+L)\n",
    "    \n",
    "    return train_dataset_joint, valid_dataset_joint, train_dataset_marginal, valid_dataset_marginal, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from utils import flatten_dict\n",
    "extractor = MongoExtractor(None, 'CPC_test')\n",
    "query = {'dataset': {'name': 'oppG', 'validation': 'ADL4-ADL5', 'test_domain': 'S1', 'L': 12, 'K': 5}, 'method': {'name': 'CPC', 'hidden': 1600, 'context': 200, 'num_gru': 1}, 'optim': {'lr': 0.0001, 'num_batch': 100, 'batch_size': 128}}\n",
    "query = flatten_dict(query)\n",
    "for result in extractor.find(query, ['config', 'info'], False, 'COMPLETED'):\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import OppG\n",
    "from opportunity import Encoder, ContextEncoder, Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = result['config']\n",
    "classifier = {\n",
    "    'pretrain': True, \n",
    "    'finetune_g': False, \n",
    "    'use_c_enc': False, \n",
    "    'finetune_c': False, \n",
    "}\n",
    "\n",
    "classifier_optim = {\n",
    "    'lr': 0.001, \n",
    "    'num_batch': 10000, \n",
    "    'batch_size': 128,\n",
    "    'monitor_per': 100, \n",
    "}\n",
    "_config['classifier'] = classifier\n",
    "_config['classifier_optim'] = classifier_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from run_sacred import get_model, get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_predict import Classifier\n",
    "\n",
    "def get_classifier(model, finetune_g, use_c_enc, finetune_c, **kwargs):\n",
    "    if use_c_enc:\n",
    "        classifier = Classifier(\n",
    "            num_classes=train_dataset.get('num_classes'),\n",
    "            g_enc=model.g_enc, c_enc=model.c_enc, finetune_g=finetune_g, finetune_c=finetune_c).cuda()\n",
    "    else:\n",
    "        classifier = Classifier(\n",
    "            num_classes=train_dataset.get('num_classes'),\n",
    "            g_enc=model.g_enc, finetune_g=finetune_g).cuda()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, _, _, test_dataset = get_dataset(**_config['dataset'])\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=_config['classifier_optim']['num_batch'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 200\n"
     ]
    }
   ],
   "source": [
    "model = get_model(input_shape=train_dataset.get('input_shape'), K=_config['dataset']['K'], **_config['method'])\n",
    "if _config['classifier']['pretrain']:\n",
    "    search_config = deepcopy(_config)\n",
    "    del search_config['classifier']\n",
    "    del search_config['classifier_optim']\n",
    "    extractor = MongoExtractor(None, _config['db_name'])\n",
    "    # TODO: Should check whether the len(list) is one or not\n",
    "    result = list(extractor.find(search_config, ['config', 'info'], False, 'COMPLETED'))[0]\n",
    "    path = os.path.join(result['info']['log_dir'], 'model_{}.pth'.format(_config['optim']['num_batch']))\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPCModel(\n",
       "  (g_enc): Encoder(\n",
       "    (feature): Sequential(\n",
       "      (0): Conv2d(1, 50, kernel_size=(1, 5), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(50, 40, kernel_size=(1, 5), stride=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(40, 20, kernel_size=(1, 3), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): Dropout(p=0.5)\n",
       "      (9): Flatten()\n",
       "      (10): Linear(in_features=4520, out_features=1600, bias=True)\n",
       "      (11): ReLU()\n",
       "      (12): Dropout(p=0.5)\n",
       "    )\n",
       "  )\n",
       "  (c_enc): ContextEncoder(\n",
       "    (gru): GRU(1600, 200)\n",
       "  )\n",
       "  (predictor): Predictor(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=200, out_features=1600, bias=True)\n",
       "      (1): Linear(in_features=200, out_features=1600, bias=True)\n",
       "      (2): Linear(in_features=200, out_features=1600, bias=True)\n",
       "      (3): Linear(in_features=200, out_features=1600, bias=True)\n",
       "      (4): Linear(in_features=200, out_features=1600, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate domain invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "def l2diff(x1, x2):\n",
    "    \"\"\"\n",
    "    standard euclidean norm\n",
    "    \"\"\"\n",
    "    return ((x1-x2)**2).sum().sqrt()\n",
    "\n",
    "\n",
    "def moment_diff(sx1, sx2, k):\n",
    "    \"\"\"\n",
    "    difference between moments\n",
    "    \"\"\"\n",
    "    ss1 = (sx1**k).mean(0)\n",
    "    ss2 = (sx2**k).mean(0)\n",
    "    return l2diff(ss1, ss2)\n",
    "\n",
    "\n",
    "class CMD(object):\n",
    "    def __init__(self, n_moments=5):\n",
    "        self.n_moments = n_moments\n",
    "\n",
    "    def __call__(self, x1, x2):\n",
    "        mx1 = x1.mean(dim=0)\n",
    "        mx2 = x2.mean(dim=0)\n",
    "        sx1 = x1 - mx1\n",
    "        sx2 = x2 - mx2\n",
    "        dm = l2diff(mx1, mx2)\n",
    "        scms = dm\n",
    "\n",
    "        for i in range(self.n_moments-1):\n",
    "            # moment diff of centralized samples\n",
    "            scms += moment_diff(sx1, sx2, i+2)\n",
    "        return scms\n",
    "\n",
    "\n",
    "def pairwise_divergence(datasets, func, criterion, batch_size=128, num_batch=None):\n",
    "    divergence = 0\n",
    "    num_total_batch = 0\n",
    "    if num_batch is None:\n",
    "        num_batch = max([len(dataset) for dataset in datasets])\n",
    "\n",
    "    for dataset1, dataset2 in itertools.combinations(datasets, 2):\n",
    "        loader1 = data.DataLoader(dataset1, shuffle=False, batch_size=batch_size)\n",
    "        loader2 = data.DataLoader(dataset2, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "        for num_iter, ((X1, Y1), (X2, Y2)) in enumerate(zip(loader1, loader2)):\n",
    "            divergence += criterion(func(X1.float().cuda()), func(X2.float().cuda())).item()\n",
    "            if ((num_iter+1) % num_batch) == 0:\n",
    "                break\n",
    "        num_total_batch += (num_iter+1)\n",
    "    return divergence/num_total_batch\n",
    "\n",
    "\n",
    "def get_feature_of(g_enc, c_enc, L):\n",
    "    def _func(X):\n",
    "        if c_enc is None:\n",
    "            return g_enc(X[..., L-1])\n",
    "        else:\n",
    "            return get_context(X[..., :(L-1)], g_enc, c_enc)\n",
    "    return _func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence_criterion = CMD(n_moments=5)\n",
    "get_g_of = get_feature_of(model.g_enc, None, _config['dataset']['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 s, sys: 676 ms, total: 36.2 s\n",
      "Wall time: 4.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.290335929393768"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pairwise_divergence(train_dataset.datasets[:2], get_g_of, divergence_criterion, num_batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_predict(\n",
    "        L, K, g_enc_size, context_size, num_gru, pretrain,  # parameters for model\n",
    "        finetune_g, use_c_enc=False, finetune_c=False,\n",
    "        num_batch=10000, iteration_at=10000):\n",
    "    \"\"\"Train label classifier.\n",
    "\n",
    "    TODO: should be separate out the data loading function and classifier building function.\n",
    "    This function should be focus on the training given classifier with given configurations\n",
    "    (like datasets or hyperparameters). The name might be just a train() then.\n",
    "\n",
    "    The ideal argments migth be similar to validate_label_prediction function, with additional\n",
    "    arguments for hyperparameters.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    pretrain : bool\n",
    "        wheter use CPC pretrained model.\n",
    "    finetune_g : bool\n",
    "        wheter train g_encoder.\n",
    "    use_c_func : bool (default False)\n",
    "        wheter use context encoder (autoregressive encoder summarize several inputs).\n",
    "    finetune_c : bool (default False)\n",
    "        wheter train context encoder. It should be false if use_c_func is False, and True\n",
    "        if use_c_func and finetune_g is both True.\n",
    "\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    Case1: pretrain=True and finetune_g=False\n",
    "    => Shallow classifier over unsupervisly learned representations\n",
    "    Case2: pretrain=False and finetune_g=True\n",
    "    => Fully supervised learning\n",
    "    Case3: pretrain=True and finetune_g=True\n",
    "    => Unsup+Sup learning\n",
    "    Case4: pretrain=False and finetune_g=False\n",
    "    => Baseline with random representations (to clarify the effect of CPC, not an architecture)\n",
    "    \"\"\"\n",
    "    if not use_c_enc and finetune_c:\n",
    "        print(\"Invalid combination of parameters\")\n",
    "        return None\n",
    "    if use_c_enc and finetune_g and not finetune_c:\n",
    "        print(\"Invalid combination of parameters\", use_c_enc, finetune_g, finetune_c)\n",
    "        return None\n",
    "\n",
    "    # Load dataset\n",
    "    # TODO: it should be easy to change the dataset\n",
    "    all_adls = ['Drill', 'ADL1', 'ADL2', 'ADL3', 'ADL4', 'ADL5']\n",
    "    valid_adls = ['ADL1', 'ADL2', 'ADL3', 'ADL4', 'ADL5']\n",
    "    train_adls = list(set(all_adls) - set(valid_adls))\n",
    "    dataset_name = '-'.join(valid_adls)\n",
    "    print(\"Load datasets ...\")\n",
    "    train_dataset = OppG(\n",
    "        'S2,S3,S4', 'Gestures', l_sample=30, interval=15, T=K+L, adl_ids=train_adls)\n",
    "    valid_dataset = OppG(\n",
    "        'S2,S3,S4', 'Gestures', l_sample=30, interval=15, T=K+L, adl_ids=valid_adls)\n",
    "    train_loader_joint = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataset = OppG('S1', 'Gestures', l_sample=30, interval=15, T=K+L)\n",
    "\n",
    "    print(\"Train: {}, Valid: {}, Test: {}\".format(\n",
    "        len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "    )\n",
    "\n",
    "    folder_name = BASE_PATH.format(g_enc_size, context_size, num_gru)\n",
    "    folder_name = '{}/{}-{}'.format(folder_name, L, K)\n",
    "    # save_folder_name = '{}/{}-{}/{}'.format(folder_name, L, K, dataset_name)\n",
    "    # print(save_folder_name)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    monitor_per = 100  # output the result per monitor_each iterations\n",
    "\n",
    "    # parameter of label train\n",
    "    g_enc = Encoder(input_shape=train_dataset.get('input_shape'), hidden_size=g_enc_size).cuda()\n",
    "    c_enc = ContextEncoder(input_shape=g_enc.output_shape(), num_layers=num_gru, hidden_size=context_size).cuda()\n",
    "    predictor = Predictor((None, c_enc.hidden_size), g_enc.output_shape()[1], max_steps=K).cuda()\n",
    "    model = CPCModel(g_enc, c_enc, predictor).cuda()\n",
    "    if pretrain:\n",
    "        model.load_state_dict(torch.load('{}-{}.pth'.format(folder_name, iteration_at)))\n",
    "\n",
    "    if use_c_enc:\n",
    "        classifier = Classifier(\n",
    "            num_classes=train_dataset.get('num_classes'),\n",
    "            g_enc=g_enc, c_enc=c_enc, finetune_g=finetune_g, finetune_c=finetune_c).cuda()\n",
    "    else:\n",
    "        classifier = Classifier(\n",
    "            num_classes=train_dataset.get('num_classes'),\n",
    "            g_enc=g_enc, finetune_g=finetune_g).cuda()\n",
    "    print(classifier)\n",
    "    # optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    train_results = []\n",
    "    valid_results = []\n",
    "    test_results = []\n",
    "    folder_name = '{}/{}/label_predict'.format(dataset_name, folder_name)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    for num_iter in range(num_batch):\n",
    "        optimizer.zero_grad()\n",
    "        X, Y = train_loader_joint.__iter__().__next__()\n",
    "        y = Y[:, 0, L-1].long().cuda()\n",
    "        pred_y = classifier(X[..., :L].float().cuda())\n",
    "        loss = criterion(pred_y, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ((num_iter + 1) % monitor_per) != 0:\n",
    "            continue\n",
    "        print(num_iter+1)\n",
    "        train_results.append(validate_label_prediction(classifier, train_dataset, L=L, nb_batch=None))\n",
    "        valid_results.append(validate_label_prediction(classifier, valid_dataset, L=L, nb_batch=None))\n",
    "        print('train', train_results[-1]['accuracy'], train_results[-1]['f1macro'])\n",
    "        print('valid', valid_results[-1]['accuracy'], valid_results[-1]['f1macro'])\n",
    "        print('test', test_results[-1]['accuracy'], test_results[-1]['f1macro'])\n",
    "        test_results.append(validate_label_prediction(classifier, test_dataset, L=L, nb_batch=None))\n",
    "        pd.DataFrame(train_results).to_csv(\n",
    "            os.path.join(folder_name, '{}-{}-{}-{}-train.csv'.format(pretrain, finetune_g, use_c_enc, finetune_c)))\n",
    "        pd.DataFrame(valid_results).to_csv(\n",
    "            os.path.join(folder_name, '{}-{}-{}-{}-valid.csv'.format(pretrain, finetune_g, use_c_enc, finetune_c)))\n",
    "        pd.DataFrame(test_results).to_csv(\n",
    "            os.path.join(folder_name, '{}-{}-{}-{}-test.csv'.format(pretrain, finetune_g, use_c_enc, finetune_c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loop 0.\n",
      "Finished loop 1.\n",
      "Finished loop 2.\n",
      "Finished loop 3.\n",
      "Finished loop 4.\n",
      "Finished loop 5.\n",
      "Finished loop 6.\n",
      "Finished loop 7.\n",
      "Finished loop 8.\n",
      "Finished loop 9.\n"
     ]
    }
   ],
   "source": [
    "from fastprogress import master_bar, progress_bar\n",
    "from time import sleep\n",
    "mb = master_bar(range(10))\n",
    "for i in mb:\n",
    "    for j in progress_bar(range(100), parent=mb):\n",
    "        sleep(0.1)\n",
    "        mb.child.comment = f'second bar stat'\n",
    "    mb.first_bar.comment = f'first bar stat'\n",
    "    mb.write(f'Finished loop {i}.')\n",
    "    #mb.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loop 0.\n",
      "Finished loop 1.\n",
      "Finished loop 2.\n",
      "Finished loop 3.\n",
      "Finished loop 4.\n",
      "Finished loop 5.\n",
      "Finished loop 6.\n",
      "Finished loop 7.\n",
      "Finished loop 8.\n",
      "Finished loop 9.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mb = master_bar(range(10))\n",
    "mb.names = ['cos', 'sin']\n",
    "for i in mb:\n",
    "    for j in progress_bar(range(100), parent=mb):\n",
    "        if j%10 == 0:\n",
    "            k = 100 * i + j\n",
    "            x = np.arange(0, 2*k*np.pi/1000, 0.01)\n",
    "            y1, y2 = np.cos(x), np.sin(x)\n",
    "            graphs = [[x,y1], [x,y2]]\n",
    "            x_bounds = [0, 2*np.pi]\n",
    "            y_bounds = [-1,1]\n",
    "            mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "            mb.child.comment = f'second bar stat'\n",
    "    mb.first_bar.comment = f'first bar stat'\n",
    "    mb.write(f'Finished loop {i}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  8.95it/s, output=g, loss=0.563, acc=0.858, message=okkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from random import random\n",
    "\n",
    "def func(c):\n",
    "    # とりあえず入力文字をそのまま返してみようと思った。\n",
    "    return c\n",
    "\n",
    "with tqdm(list(\"abcdefg\")) as pbar:\n",
    "    for i, char in enumerate(pbar):\n",
    "        sleep(0.1)\n",
    "        pbar.set_postfix(OrderedDict(\n",
    "            output=func(char), loss=random(), acc=random(), message='okkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk'))\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = OrderedDict()\n",
    "dic['acc'] = 0.8\n",
    "dic['loss'] = 0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-58-91c4ef0e72fc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-91c4ef0e72fc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for k, v in dic.items():\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "text = ', '.join(['{}:{:.3f}'.format(k, v) for k, v in dic.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.800, loss:0.230\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
