{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、Bをバッチサイズ、Cをチャネル数、Wをウィンドウサイズ、Lをコンテキスト長、Kを予測長とする。\n",
    "\n",
    "* Context: (B, C, W, L)\n",
    "* Positive Sampleを1個（B, C, W, K)\n",
    "* Negative Samples (B, C, W, K)\n",
    "  * same seq, different loc\n",
    "  * same user, different seq\n",
    "  * different user, different seq\n",
    "\n",
    "* 方針1：Samplerで頑張る\n",
    "  * Pro：データセットは基本的に今のままでいい\n",
    "  * Con:NegativeのSamplerもSamplerを複数作れば色んな種類を試しやすい\n",
    "  * Con:Samplerの仕様をよく把握してない、最終的なコードがわかりにくくなる\n",
    "* 方針2:データセット自体で頑張る\n",
    "  * Pro:多分簡単\n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Correspond to g_enc in the CPC paper\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, hidden_size=400, activation='relu'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_shape = input_shape\n",
    "        linear_size = 20 * input_shape[1] * 2\n",
    "\n",
    "        if activation == 'relu':\n",
    "            activation = nn.ReLU\n",
    "        elif activation == 'lrelu':\n",
    "            activation = nn.LeakyReLU\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 50, kernel_size=(1, 5)), \n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)), \n",
    "            nn.Conv2d(50, 40, kernel_size=(1, 5)), \n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)), \n",
    "            nn.Conv2d(40, 20, kernel_size=(1, 3)), \n",
    "            activation(),\n",
    "            nn.Dropout(0.5),\n",
    "            Flatten(),\n",
    "            nn.Linear(linear_size, self.hidden_size), \n",
    "            activation(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        feature = self.feature(input_data)\n",
    "        return feature\n",
    "\n",
    "    def output_shape(self):\n",
    "        return (None, self.hidden_size)\n",
    "    \n",
    "    \n",
    "class ContextEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Some autoregressive models to emmbedding observations into a context vector. We use GRU here. \n",
    "    \n",
    "    Caution: in the original paper, they say, \"The output of the GRU at every timestep is used as the context c\", \n",
    "    but this code only uses final output of the GRU. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, hidden_size=200, num_layers=2):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = 200\n",
    "        self.gru = nn.GRU(input_shape[1], hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h0 = Variable(torch.zeros(self.num_layers, X.shape[1], self.hidden_size)).cuda()\n",
    "        return self.gru(X, h0)\n",
    "    \n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Predict the k step forward future using a context vector c, and k dependent weight matrix. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, hidden_size, max_steps):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.max_steps = max_steps\n",
    "        self.linears = nn.ModuleList([nn.Linear(input_shape[1], hidden_size) for i in range(max_steps)])\n",
    "        \n",
    "    def forward(self, c, k):\n",
    "        \"\"\"\n",
    "        predict the k step forward future from the context vector c\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        c : torch.Variable\n",
    "            context vector\n",
    "        k : int\n",
    "            the number of forward steps, which is used to determine the weight matrix \n",
    "        \"\"\"\n",
    "        \n",
    "        return self.linears[k](c)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "\n",
    "from datasets import OppG\n",
    "import torch.utils.data as data\n",
    "K = 3 # maximum prediction steps (sequence length of future sequences)\n",
    "L = 12  # context size\n",
    "\n",
    "dataset = OppG('S1', 'Gestures', l_sample=30, interval=15, T=K+L)\n",
    "loader = data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "neg_dataset = OppG('S2', 'Gestures', l_sample=30, interval=15, T=K)  # marginal sample come from a different user for simplicity\n",
    "neg_loader = data.DataLoader(neg_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 50, kernel_size=(1, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(50, 40, kernel_size=(1, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(40, 20, kernel_size=(1, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5)\n",
      "    (9): Flatten()\n",
      "    (10): Linear(in_features=4520, out_features=100, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "ContextEncoder(\n",
      "  (gru): GRU(100, 200, num_layers=2)\n",
      ")\n",
      "Predictor(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize network\n",
    "\n",
    "g_enc = Encoder(input_shape=dataset.get('input_shape'), hidden_size=100).cuda()\n",
    "c_enc = ContextEncoder(input_shape=g_enc.output_shape(), num_layers=2, hidden_size=50).cuda()\n",
    "predictor = Predictor((None, c_enc.hidden_size), g_enc.output_shape()[1], max_steps=K).cuda()\n",
    "\n",
    "print(g_enc)\n",
    "print(c_enc)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(X, g_enc, c_enc):\n",
    "    z_context = []\n",
    "    nb_context = X.shape[-1]\n",
    "\n",
    "    h = Variable(torch.zeros(X.shape[0], c_enc.hidden_size).cuda(), requires_grad=False)\n",
    "    for i in range(nb_context):\n",
    "        z_context.append(g_enc(X[..., i]))\n",
    "\n",
    "    o, h = c_enc(torch.stack(z_context))\n",
    "    c = h[-1]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.6900404691696167\n",
      "20 0.6866204142570496\n",
      "30 0.6744613647460938\n",
      "40 0.6368961334228516\n",
      "50 0.5539376735687256\n",
      "60 0.4298185110092163\n",
      "70 0.3314841091632843\n",
      "80 0.2630160450935364\n",
      "90 0.22764258086681366\n",
      "100 0.16308638453483582\n",
      "110 0.1586257666349411\n",
      "120 0.14230069518089294\n",
      "130 0.15530186891555786\n",
      "140 0.09757449477910995\n",
      "150 0.0972842201590538\n",
      "160 0.08111138641834259\n",
      "170 0.06529131531715393\n",
      "180 0.059362005442380905\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(list(g_enc.parameters()) + list(c_enc.parameters()) + list(predictor.parameters()), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "for num_iter in range(1000):\n",
    "    X, _ = loader.__iter__().__next__()\n",
    "    X_m, _ = neg_loader.__iter__().__next__()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    X = Variable(X.float()).cuda()\n",
    "    X_m = Variable(X_m.float()).cuda()\n",
    "    c = get_context(X[..., :L], g_enc, c_enc)\n",
    "    loss = 0\n",
    "    for i in range(K):\n",
    "        z_j = g_enc(X[..., L+i]) \n",
    "        z_m = g_enc(X_m[..., i])\n",
    "        z_p = predictor(c, i)\n",
    "        score_j = torch.sigmoid(torch.bmm(z_j.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))\n",
    "        score_m = torch.sigmoid(torch.bmm(z_m.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))\n",
    "        loss += criterion(score_j, Variable(torch.ones((len(score_j), 1))).cuda()) + criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())\n",
    "        # loss += criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())\n",
    "    loss = loss / (2*K)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (num_iter+1) % 10 == 0:\n",
    "        print(num_iter+1, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " 1.00000e-03 *\n",
       "   1.3218\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       " 1.00000e-03 *\n",
       "   3.8247\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(score_j, Variable(torch.ones((len(score_j), 1))).cuda()), criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
