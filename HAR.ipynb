{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、Bをバッチサイズ、Cをチャネル数、Wをウィンドウサイズ、Lをコンテキスト長、Tを予測長とする。\n",
    "\n",
    "* Context: (B, C, W, L, 1)\n",
    "* Positive Sampleを1個（B, C, W, T, 1)\n",
    "* Negative Samples (B, C, W, T)\n",
    "  * same seq, different loc\n",
    "  * same user, different seq\n",
    "  * different user, different seq\n",
    "\n",
    "* 方針1：Samplerで頑張る\n",
    "  * Pro：データセットは基本的に今のままでいい\n",
    "  * Con:NegativeのSamplerもSamplerを複数作れば色んな種類を試しやすい\n",
    "  * Con:Samplerの仕様をよく把握してない、最終的なコードがわかりにくくなる\n",
    "* 方針2:データセット自体で頑張る\n",
    "  * Pro:多分簡単\n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ContextEncoderCell(nn.Module):\\n    def __init__(self, input_shape, hidden_size=200):\\n        super(ContextEncoderCell, self).__init__()\\n        self.hidden_size = hidden_size\\n        self.gru = nn.GRUCell(input_shape[1], hidden_size=self.hidden_size)\\n        \\n    def forward(self, X, h):\\n        return self.gru(X, h) \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=400, activation='relu'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_shape = input_shape\n",
    "        linear_size = 20 * input_shape[1] * 2\n",
    "\n",
    "        if activation == 'relu':\n",
    "            activation = nn.ReLU\n",
    "        elif activation == 'lrelu':\n",
    "            activation = nn.LeakyReLU\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 50, kernel_size=(1, 5)), \n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)), \n",
    "            nn.Conv2d(50, 40, kernel_size=(1, 5)), \n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)), \n",
    "            nn.Conv2d(40, 20, kernel_size=(1, 3)), \n",
    "            activation(),\n",
    "            nn.Dropout(0.5),\n",
    "            Flatten(),\n",
    "            nn.Linear(linear_size, self.hidden_size), \n",
    "            activation(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        feature = self.feature(input_data)\n",
    "        return feature\n",
    "\n",
    "    def output_shape(self):\n",
    "        return (None, self.hidden_size)\n",
    "    \n",
    "    \n",
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=200, num_layers=2):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = 200\n",
    "        self.gru = nn.GRU(input_shape[1], hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h0 = Variable(torch.zeros(self.num_layers, X.shape[1], self.hidden_size)).cuda()\n",
    "        return self.gru(X, h0)\n",
    "    \n",
    "\n",
    "        \n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size, max_steps):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.max_steps = max_steps\n",
    "        self.linears = nn.ModuleList([nn.Linear(input_shape[1], hidden_size) for i in range(max_steps)])\n",
    "        \n",
    "    def forward(self, c, k):\n",
    "        \"\"\"\n",
    "        predict the k step forward future from the context vector c\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        c : torch.Variable\n",
    "            context vector\n",
    "        k : int\n",
    "            the number of forward steps, which is used to determine the weight matrix \n",
    "        \"\"\"\n",
    "        \n",
    "        return self.linears[k](c)\n",
    "    \n",
    "    \n",
    "def predictor_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.fill_(0.00) # copy_(torch.zeros_like(m.weight.data))\n",
    "        m.bias.data.fill_(0.00)\n",
    "    \n",
    "# predictor.apply(predictor_init)\n",
    "\"\"\"\n",
    "class ContextEncoderCell(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=200):\n",
    "        super(ContextEncoderCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRUCell(input_shape[1], hidden_size=self.hidden_size)\n",
    "        \n",
    "    def forward(self, X, h):\n",
    "        return self.gru(X, h) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import _SingleUserSingleADL, OppG\n",
    "import torch.utils.data as data\n",
    "T = 3 # maximum prediction steps (sequence length of future sequences)\n",
    "L = 12  # context size\n",
    "\n",
    "dataset = OppG('S1', 'Gestures', l_sample=30, interval=15, T=T+L)\n",
    "loader = data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "neg_dataset = OppG('S2', 'Gestures', l_sample=30, interval=15, T=T)  # marginal sample come from a different user for simplicity\n",
    "neg_loader = data.DataLoader(neg_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 50, kernel_size=(1, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (3): Conv2d(50, 40, kernel_size=(1, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (6): Conv2d(40, 20, kernel_size=(1, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5)\n",
      "    (9): Flatten(\n",
      "    )\n",
      "    (10): Linear(in_features=4520, out_features=100, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.5)\n",
      "  )\n",
      ")\n",
      "ContextEncoder(\n",
      "  (gru): GRU(100, 200, num_layers=2)\n",
      ")\n",
      "Predictor(\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "g_enc = Encoder(input_shape=dataset.get('input_shape'), hidden_size=100).cuda()\n",
    "c_enc = ContextEncoder(input_shape=g_enc.output_shape(), num_layers=2, hidden_size=50).cuda()\n",
    "predictor = Predictor((None, c_enc.hidden_size), g_enc.output_shape()[1], max_steps=T).cuda()\n",
    "# predictor.apply(predictor_init)\n",
    "\n",
    "print(g_enc)\n",
    "print(c_enc)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(X, g_enc, c_enc):\n",
    "    z_context = []\n",
    "    nb_context = X.shape[-1]\n",
    "\n",
    "    h = Variable(torch.zeros(X.shape[0], c_enc.hidden_size).cuda(), requires_grad=False)\n",
    "    for i in range(nb_context):\n",
    "        z_context.append(g_enc(X[..., i]))\n",
    "\n",
    "    o, h = c_enc(torch.stack(z_context))\n",
    "    c = h[-1]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.6918329000473022)\n",
      "(20, 0.6870383620262146)\n",
      "(30, 0.6842116117477417)\n",
      "(40, 0.6404867172241211)\n",
      "(50, 0.566656231880188)\n",
      "(60, 0.48404228687286377)\n",
      "(70, 0.4226868152618408)\n",
      "(80, 0.3439512252807617)\n",
      "(90, 0.3530319333076477)\n",
      "(100, 0.2860561013221741)\n",
      "(110, 0.2278597056865692)\n",
      "(120, 0.19529810547828674)\n",
      "(130, 0.17787134647369385)\n",
      "(140, 0.11570079624652863)\n",
      "(150, 0.1130598783493042)\n",
      "(160, 0.1038263663649559)\n",
      "(170, 0.12228446453809738)\n",
      "(180, 0.11137580871582031)\n",
      "(190, 0.08600395917892456)\n",
      "(200, 0.07485218346118927)\n",
      "(210, 0.04993542283773422)\n",
      "(220, 0.0547170452773571)\n",
      "(230, 0.054931506514549255)\n",
      "(240, 0.053934745490550995)\n",
      "(250, 0.029630355536937714)\n",
      "(260, 0.03375762328505516)\n",
      "(270, 0.028681498020887375)\n",
      "(280, 0.050952088087797165)\n",
      "(290, 0.030947193503379822)\n",
      "(300, 0.02747584506869316)\n",
      "(310, 0.01894466020166874)\n",
      "(320, 0.03502185270190239)\n",
      "(330, 0.04334148019552231)\n",
      "(340, 0.01848229393362999)\n",
      "(350, 0.02440539561212063)\n",
      "(360, 0.013370182365179062)\n",
      "(370, 0.019521210342645645)\n",
      "(380, 0.02374095283448696)\n",
      "(390, 0.03080468624830246)\n",
      "(400, 0.025478098541498184)\n",
      "(410, 0.021913502365350723)\n",
      "(420, 0.032811831682920456)\n",
      "(430, 0.017786145210266113)\n",
      "(440, 0.023304840549826622)\n",
      "(450, 0.014246419072151184)\n",
      "(460, 0.008888494223356247)\n",
      "(470, 0.011562250554561615)\n",
      "(480, 0.02562575414776802)\n",
      "(490, 0.025754299014806747)\n",
      "(500, 0.01667199097573757)\n",
      "(510, 0.015129072591662407)\n",
      "(520, 0.013556847348809242)\n",
      "(530, 0.01081475242972374)\n",
      "(540, 0.016541674733161926)\n",
      "(550, 0.023774001747369766)\n",
      "(560, 0.013930870220065117)\n",
      "(570, 0.014383235946297646)\n",
      "(580, 0.0109733697026968)\n",
      "(590, 0.012676692567765713)\n",
      "(600, 0.02050715684890747)\n",
      "(610, 0.010379677638411522)\n",
      "(620, 0.01115996390581131)\n",
      "(630, 0.008024818263947964)\n",
      "(640, 0.01928175427019596)\n",
      "(650, 0.016351742669939995)\n",
      "(660, 0.006415958516299725)\n",
      "(670, 0.00723836338147521)\n",
      "(680, 0.008961702696979046)\n",
      "(690, 0.017790455371141434)\n",
      "(700, 0.005700502544641495)\n",
      "(710, 0.0059846206568181515)\n",
      "(720, 0.008266881108283997)\n",
      "(730, 0.0077315024100244045)\n",
      "(740, 0.005581976380199194)\n",
      "(750, 0.010193463414907455)\n",
      "(760, 0.00911631528288126)\n",
      "(770, 0.015232264064252377)\n",
      "(780, 0.007114920765161514)\n",
      "(790, 0.008388541638851166)\n",
      "(800, 0.008682251907885075)\n",
      "(810, 0.007492139469832182)\n",
      "(820, 0.016675233840942383)\n",
      "(830, 0.008360465988516808)\n",
      "(840, 0.0032891868613660336)\n",
      "(850, 0.013709369115531445)\n",
      "(860, 0.007579030003398657)\n",
      "(870, 0.0032841740176081657)\n",
      "(880, 0.007543183863162994)\n",
      "(890, 0.014919159933924675)\n",
      "(900, 0.0069122351706027985)\n",
      "(910, 0.006119152531027794)\n",
      "(920, 0.016421064734458923)\n",
      "(930, 0.01463183294981718)\n",
      "(940, 0.004956475459039211)\n",
      "(950, 0.008729522116482258)\n",
      "(960, 0.017991188913583755)\n",
      "(970, 0.00887647457420826)\n",
      "(980, 0.003315563080832362)\n",
      "(990, 0.006952936761081219)\n",
      "(1000, 0.008148780092597008)\n",
      "(1010, 0.0073620229959487915)\n",
      "(1020, 0.007182030938565731)\n",
      "(1030, 0.005213855765759945)\n",
      "(1040, 0.006302729249000549)\n",
      "(1050, 0.003655843436717987)\n",
      "(1060, 0.003475830890238285)\n",
      "(1070, 0.002310784999281168)\n",
      "(1080, 0.0031134006567299366)\n",
      "(1090, 0.005186059512197971)\n",
      "(1100, 0.0035947668366134167)\n",
      "(1110, 0.007431644015014172)\n",
      "(1120, 0.004793837666511536)\n",
      "(1130, 0.004808668978512287)\n",
      "(1140, 0.0047749425284564495)\n",
      "(1150, 0.005637217313051224)\n",
      "(1160, 0.002598733641207218)\n",
      "(1170, 0.003902464872226119)\n",
      "(1180, 0.005739141255617142)\n",
      "(1190, 0.005872930400073528)\n",
      "(1200, 0.007299751043319702)\n",
      "(1210, 0.005126189440488815)\n",
      "(1220, 0.005110976751893759)\n",
      "(1230, 0.003176423255354166)\n",
      "(1240, 0.004264521412551403)\n",
      "(1250, 0.005533733870834112)\n",
      "(1260, 0.0026322808116674423)\n",
      "(1270, 0.007360875606536865)\n",
      "(1280, 0.0012670273426920176)\n",
      "(1290, 0.004159256815910339)\n",
      "(1300, 0.002896558493375778)\n",
      "(1310, 0.0026247184723615646)\n",
      "(1320, 0.004066146910190582)\n",
      "(1330, 0.0017011540476232767)\n",
      "(1340, 0.0038132041227072477)\n",
      "(1350, 0.003601628355681896)\n",
      "(1360, 0.0018976358696818352)\n",
      "(1370, 0.002865917980670929)\n",
      "(1380, 0.006988277658820152)\n",
      "(1390, 0.0038169920444488525)\n",
      "(1400, 0.005182421300560236)\n",
      "(1410, 0.005787865724414587)\n",
      "(1420, 0.005276975687593222)\n",
      "(1430, 0.004941422026604414)\n",
      "(1440, 0.0037376051768660545)\n",
      "(1450, 0.004917028360068798)\n",
      "(1460, 0.006189634092152119)\n",
      "(1470, 0.0013818626757711172)\n",
      "(1480, 0.004176780581474304)\n",
      "(1490, 0.0016092382138594985)\n",
      "(1500, 0.002368359826505184)\n",
      "(1510, 0.0066957660019397736)\n",
      "(1520, 0.005339278839528561)\n",
      "(1530, 0.0014878662768751383)\n",
      "(1540, 0.003868398955091834)\n",
      "(1550, 0.004249922931194305)\n",
      "(1560, 0.0024847949389368296)\n",
      "(1570, 0.002868822542950511)\n",
      "(1580, 0.0008297268068417907)\n",
      "(1590, 0.001782596460543573)\n",
      "(1600, 0.004180768504738808)\n",
      "(1610, 0.0020843271631747484)\n",
      "(1620, 0.005956382490694523)\n",
      "(1630, 0.0005501793930307031)\n",
      "(1640, 0.0005431931931525469)\n",
      "(1650, 0.002836184110492468)\n",
      "(1660, 0.003019344760105014)\n",
      "(1670, 0.00523502379655838)\n",
      "(1680, 0.0033628828823566437)\n",
      "(1690, 0.005051974207162857)\n",
      "(1700, 0.002824479481205344)\n",
      "(1710, 0.00134340301156044)\n",
      "(1720, 0.0017635864205658436)\n",
      "(1730, 0.0037525584921240807)\n",
      "(1740, 0.006501407362520695)\n",
      "(1750, 0.00353642157278955)\n",
      "(1760, 0.0003379174740985036)\n",
      "(1770, 0.0018094488186761737)\n",
      "(1780, 0.0016498386394232512)\n",
      "(1790, 0.006268777884542942)\n",
      "(1800, 0.0011699454626068473)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5a8500e37625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mpy_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/torch/functional.pyc\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(list(g_enc.parameters()) + list(c_enc.parameters()) + list(predictor.parameters()), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "for num_iter in range(10000):\n",
    "    X, _ = loader.__iter__().__next__()\n",
    "    X_m, _ = neg_loader.__iter__().__next__()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    X = Variable(X.float()).cuda()\n",
    "    X_m = Variable(X_m.float()).cuda()\n",
    "    c = get_context(X[..., :L], g_enc, c_enc)\n",
    "    loss = 0\n",
    "    for i in range(T):\n",
    "        z_j = g_enc(X[..., L+i]) \n",
    "        z_m = g_enc(X_m[..., i])\n",
    "        z_p = predictor(c, i)\n",
    "        score_j = torch.sigmoid(torch.bmm(z_j.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))\n",
    "        score_m = torch.sigmoid(torch.bmm(z_m.unsqueeze(1), z_p.unsqueeze(2)).squeeze(2))\n",
    "        loss += criterion(score_j, Variable(torch.ones((len(score_j), 1))).cuda()) + criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())\n",
    "        # loss += criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())\n",
    "    loss = loss / (2*T) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (num_iter+1) % 10 == 0:\n",
    "        print(num_iter+1, loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " 1.00000e-03 *\n",
       "   1.3218\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       " 1.00000e-03 *\n",
       "   3.8247\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(score_j, Variable(torch.ones((len(score_j), 1))).cuda()), criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.5376\n",
       " 0.0000\n",
       "-0.2556\n",
       " 0.2598\n",
       " 0.0334\n",
       " 0.3356\n",
       " 0.1516\n",
       " 0.3498\n",
       " 0.1674\n",
       "-0.2075\n",
       "-0.5773\n",
       "-0.4136\n",
       "-0.4082\n",
       "-0.2005\n",
       "-0.2326\n",
       " 0.1670\n",
       " 0.4051\n",
       "-0.3416\n",
       " 0.1434\n",
       " 0.0000\n",
       "-0.3829\n",
       " 0.2251\n",
       " 0.2381\n",
       "-0.3092\n",
       "-0.3388\n",
       " 0.5055\n",
       " 0.3117\n",
       "-0.3075\n",
       " 0.1922\n",
       " 0.2009\n",
       " 0.3714\n",
       "-0.2663\n",
       "-0.3674\n",
       "-0.4595\n",
       " 0.2275\n",
       " 0.1806\n",
       " 0.5348\n",
       "-0.2914\n",
       " 0.3089\n",
       " 0.4450\n",
       "-0.3086\n",
       "-0.3533\n",
       "-0.3393\n",
       " 0.1842\n",
       "-0.3149\n",
       "-0.3159\n",
       " 0.3443\n",
       " 0.1646\n",
       "-0.4574\n",
       " 0.2962\n",
       " 0.3052\n",
       " 0.2909\n",
       "-0.4097\n",
       "-0.1889\n",
       " 0.1828\n",
       " 0.3752\n",
       "-0.3989\n",
       "-0.1065\n",
       " 0.4027\n",
       " 0.4138\n",
       "-0.3753\n",
       " 0.4191\n",
       "-0.0154\n",
       "-0.1927\n",
       " 0.5721\n",
       " 0.1792\n",
       "-0.1974\n",
       "-0.3906\n",
       "-0.4063\n",
       "-0.9203\n",
       " 0.4499\n",
       "-0.4651\n",
       "-0.4710\n",
       " 0.1755\n",
       " 0.0000\n",
       " 0.2089\n",
       " 0.3390\n",
       "-0.3094\n",
       "-0.4811\n",
       " 0.1548\n",
       " 0.3919\n",
       " 0.4328\n",
       "-0.5044\n",
       " 0.2818\n",
       "-0.3609\n",
       "-0.4347\n",
       "-0.1564\n",
       "-0.0942\n",
       " 0.2925\n",
       "-0.3358\n",
       "-0.3748\n",
       " 0.2301\n",
       "-0.4198\n",
       "-0.4209\n",
       "-0.3177\n",
       "-0.3782\n",
       "-0.0321\n",
       " 0.3876\n",
       "-0.2524\n",
       " 0.3748\n",
       "[torch.cuda.FloatTensor of size 100 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for i in range(T):\n",
    "    z_j = g_enc(X[..., L+i]) \n",
    "    z_m = g_enc(X[..., -i])  # Replace here\n",
    "    z_p = predictor(c, i)\n",
    "    score_j = torch.sigmoid(torch.bmm(z_j.unsqueeze(1), z_p.unsqueeze(2)).squeeze(1))\n",
    "    score_m = torch.sigmoid(torch.bmm(z_m.unsqueeze(1), z_m.unsqueeze(2)).squeeze(1))\n",
    "    loss = criterion(score_j, Variable(torch.ones((len(score_j), 1))).cuda()) + criterion(score_m, Variable(torch.zeros((len(score_j), 1))).cuda())\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.6947\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 400]), torch.Size([128, 400, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 400])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
